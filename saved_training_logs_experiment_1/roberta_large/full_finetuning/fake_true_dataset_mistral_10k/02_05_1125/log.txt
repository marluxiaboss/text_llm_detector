log_loss_steps: 208
eval_steps: 512
check_degradation: 512
Average Loss on fact answering task after 0 samples: 5.1951
Average Loss on fact answering task after 0 samples: 5.3846
Average Loss on fact answering task after 0 samples: 5.3067
Average Loss on fact answering task after 0 samples: 5.2418
Average Loss on fact answering task after 0 samples: 5.1243
----------------Epoch 1/1----------------
Epoch 1/1, Loss after 192 samples: 0.7154
Epoch 1/1, Loss after 400 samples: 0.7116
Average Loss on fact answering task after 496 samples: 5.2416
Average Loss on fact answering task after 496 samples: 5.3726
Average Loss on fact answering task after 496 samples: 5.2595
Average Loss on fact answering task after 496 samples: 5.2684
Average Loss on fact answering task after 496 samples: 5.4260
Mean accuracy: 0.6010, std: 0.0112, lower bound: 0.5791, upper bound: 0.6232 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 496 samples: 0.6009
Best model with eval accuracy 0.6009127789046653 with 496 samples seen is saved
Epoch 1/1, Loss after 608 samples: 0.6833
Epoch 1/1, Loss after 816 samples: 0.6523
Average Loss on fact answering task after 1008 samples: 5.2200
Average Loss on fact answering task after 1008 samples: 5.1513
Average Loss on fact answering task after 1008 samples: 5.4003
Average Loss on fact answering task after 1008 samples: 5.2127
Average Loss on fact answering task after 1008 samples: 5.1456
Mean accuracy: 0.7619, std: 0.0099, lower bound: 0.7429, upper bound: 0.7809 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1008 samples: 0.7612
Best model with eval accuracy 0.7611561866125761 with 1008 samples seen is saved
Epoch 1/1, Loss after 1024 samples: 0.6108
Epoch 1/1, Loss after 1232 samples: 0.5759
Epoch 1/1, Loss after 1440 samples: 0.5351
Average Loss on fact answering task after 1520 samples: 5.1143
Average Loss on fact answering task after 1520 samples: 5.4097
Average Loss on fact answering task after 1520 samples: 5.2390
Average Loss on fact answering task after 1520 samples: 5.2647
Average Loss on fact answering task after 1520 samples: 5.4164
Mean accuracy: 0.7947, std: 0.0093, lower bound: 0.7759, upper bound: 0.8119 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1520 samples: 0.7951
Best model with eval accuracy 0.795131845841785 with 1520 samples seen is saved
Epoch 1/1, Loss after 1648 samples: 0.4725
Epoch 1/1, Loss after 1856 samples: 0.5573
Average Loss on fact answering task after 2032 samples: 5.4753
Average Loss on fact answering task after 2032 samples: 5.3661
Average Loss on fact answering task after 2032 samples: 5.3865
Average Loss on fact answering task after 2032 samples: 5.3958
Average Loss on fact answering task after 2032 samples: 5.4280
Mean accuracy: 0.8497, std: 0.0080, lower bound: 0.8337, upper bound: 0.8646 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2032 samples: 0.8494
Best model with eval accuracy 0.8493914807302231 with 2032 samples seen is saved
Epoch 1/1, Loss after 2064 samples: 0.4796
Epoch 1/1, Loss after 2272 samples: 0.3981
Epoch 1/1, Loss after 2480 samples: 0.3492
Average Loss on fact answering task after 2544 samples: 5.5111
Average Loss on fact answering task after 2544 samples: 5.5102
Average Loss on fact answering task after 2544 samples: 5.3086
Average Loss on fact answering task after 2544 samples: 5.4277
Average Loss on fact answering task after 2544 samples: 5.6364
Mean accuracy: 0.8535, std: 0.0079, lower bound: 0.8377, upper bound: 0.8687 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2544 samples: 0.8534
Best model with eval accuracy 0.853448275862069 with 2544 samples seen is saved
Epoch 1/1, Loss after 2688 samples: 0.3650
Epoch 1/1, Loss after 2896 samples: 0.2727
Average Loss on fact answering task after 3056 samples: 5.7479
Average Loss on fact answering task after 3056 samples: 5.5065
Average Loss on fact answering task after 3056 samples: 5.6190
Average Loss on fact answering task after 3056 samples: 5.6145
Average Loss on fact answering task after 3056 samples: 5.8142
Mean accuracy: 0.8057, std: 0.0096, lower bound: 0.7865, upper bound: 0.8240 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3056 samples: 0.8058
Epoch 1/1, Loss after 3104 samples: 0.3313
Epoch 1/1, Loss after 3312 samples: 0.2744
Epoch 1/1, Loss after 3520 samples: 0.3221
Average Loss on fact answering task after 3568 samples: 5.7393
Average Loss on fact answering task after 3568 samples: 5.6572
Average Loss on fact answering task after 3568 samples: 5.6743
Average Loss on fact answering task after 3568 samples: 5.8325
Average Loss on fact answering task after 3568 samples: 5.6936
Mean accuracy: 0.8730, std: 0.0072, lower bound: 0.8585, upper bound: 0.8864 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3568 samples: 0.8727
Best model with eval accuracy 0.8727180527383367 with 3568 samples seen is saved
Epoch 1/1, Loss after 3728 samples: 0.2431
Epoch 1/1, Loss after 3936 samples: 0.2682
Average Loss on fact answering task after 4080 samples: 5.5586
Average Loss on fact answering task after 4080 samples: 5.6819
Average Loss on fact answering task after 4080 samples: 5.7987
Average Loss on fact answering task after 4080 samples: 5.5315
Average Loss on fact answering task after 4080 samples: 5.4474
Mean accuracy: 0.9137, std: 0.0063, lower bound: 0.9016, upper bound: 0.9260 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4080 samples: 0.9138
Best model with eval accuracy 0.9137931034482759 with 4080 samples seen is saved
Epoch 1/1, Loss after 4144 samples: 0.3562
Epoch 1/1, Loss after 4352 samples: 0.2908
Epoch 1/1, Loss after 4560 samples: 0.1848
Average Loss on fact answering task after 4592 samples: 5.7521
Average Loss on fact answering task after 4592 samples: 5.8460
Average Loss on fact answering task after 4592 samples: 5.8381
Average Loss on fact answering task after 4592 samples: 5.6507
Average Loss on fact answering task after 4592 samples: 5.7485
Mean accuracy: 0.8011, std: 0.0093, lower bound: 0.7824, upper bound: 0.8190 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4592 samples: 0.8007
Epoch 1/1, Loss after 4768 samples: 0.1952
Epoch 1/1, Loss after 4976 samples: 0.2586
Average Loss on fact answering task after 5104 samples: 5.6780
Average Loss on fact answering task after 5104 samples: 5.6353
Average Loss on fact answering task after 5104 samples: 5.6935
Average Loss on fact answering task after 5104 samples: 5.7507
Average Loss on fact answering task after 5104 samples: 5.8698
Mean accuracy: 0.8890, std: 0.0073, lower bound: 0.8737, upper bound: 0.9026 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5104 samples: 0.8889
Epoch 1/1, Loss after 5184 samples: 0.1476
Epoch 1/1, Loss after 5392 samples: 0.2469
Epoch 1/1, Loss after 5600 samples: 0.2401
Average Loss on fact answering task after 5616 samples: 5.9604
Average Loss on fact answering task after 5616 samples: 5.9581
Average Loss on fact answering task after 5616 samples: 5.7529
Average Loss on fact answering task after 5616 samples: 5.8203
Average Loss on fact answering task after 5616 samples: 6.1663
Mean accuracy: 0.9154, std: 0.0060, lower bound: 0.9042, upper bound: 0.9275 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5616 samples: 0.9158
Best model with eval accuracy 0.9158215010141988 with 5616 samples seen is saved
Epoch 1/1, Loss after 5808 samples: 0.2354
Epoch 1/1, Loss after 6016 samples: 0.1676
Average Loss on fact answering task after 6128 samples: 5.8731
Average Loss on fact answering task after 6128 samples: 5.9165
Average Loss on fact answering task after 6128 samples: 5.9784
Average Loss on fact answering task after 6128 samples: 6.0190
Average Loss on fact answering task after 6128 samples: 5.8673
Mean accuracy: 0.9185, std: 0.0065, lower bound: 0.9052, upper bound: 0.9305 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6128 samples: 0.9184
Best model with eval accuracy 0.9183569979716024 with 6128 samples seen is saved
Epoch 1/1, Loss after 6224 samples: 0.2090
Epoch 1/1, Loss after 6432 samples: 0.1930
Epoch 1/1, Loss after 6640 samples: 0.1469
Average Loss on fact answering task after 6640 samples: 6.2006
Average Loss on fact answering task after 6640 samples: 5.9731
Average Loss on fact answering task after 6640 samples: 6.0925
Average Loss on fact answering task after 6640 samples: 6.1416
Average Loss on fact answering task after 6640 samples: 6.1384
Mean accuracy: 0.8343, std: 0.0084, lower bound: 0.8180, upper bound: 0.8509 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6640 samples: 0.8342
Epoch 1/1, Loss after 6848 samples: 0.1517
Epoch 1/1, Loss after 7056 samples: 0.1551
Average Loss on fact answering task after 7152 samples: 6.2241
Average Loss on fact answering task after 7152 samples: 6.0907
Average Loss on fact answering task after 7152 samples: 6.1860
Average Loss on fact answering task after 7152 samples: 6.0477
Average Loss on fact answering task after 7152 samples: 6.2532
Mean accuracy: 0.9235, std: 0.0061, lower bound: 0.9123, upper bound: 0.9356 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7152 samples: 0.9234
Best model with eval accuracy 0.9234279918864098 with 7152 samples seen is saved
Epoch 1/1, Loss after 7264 samples: 0.1898
Epoch 1/1, Loss after 7472 samples: 0.1838
Average Loss on fact answering task after 7664 samples: 5.9455
Average Loss on fact answering task after 7664 samples: 6.1263
Average Loss on fact answering task after 7664 samples: 5.9200
Average Loss on fact answering task after 7664 samples: 6.1560
Average Loss on fact answering task after 7664 samples: 5.9784
Mean accuracy: 0.9420, std: 0.0052, lower bound: 0.9315, upper bound: 0.9513 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7664 samples: 0.9422
Best model with eval accuracy 0.9421906693711968 with 7664 samples seen is saved
Epoch 1/1, Loss after 7680 samples: 0.1721
Epoch 1/1, Loss after 7888 samples: 0.2178
Epoch 1/1, Loss after 8096 samples: 0.1369
Average Loss on fact answering task after 8176 samples: 6.0787
Average Loss on fact answering task after 8176 samples: 6.1521
Average Loss on fact answering task after 8176 samples: 6.0481
Average Loss on fact answering task after 8176 samples: 5.8598
Average Loss on fact answering task after 8176 samples: 6.1735
Mean accuracy: 0.9088, std: 0.0066, lower bound: 0.8960, upper bound: 0.9209 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8176 samples: 0.9087
Epoch 1/1, Loss after 8304 samples: 0.1455
Epoch 1/1, Loss after 8512 samples: 0.0715
Average Loss on fact answering task after 8688 samples: 6.1975
Average Loss on fact answering task after 8688 samples: 5.9614
Average Loss on fact answering task after 8688 samples: 5.9982
Average Loss on fact answering task after 8688 samples: 5.9875
Average Loss on fact answering task after 8688 samples: 6.0099
Mean accuracy: 0.8772, std: 0.0077, lower bound: 0.8626, upper bound: 0.8920 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8688 samples: 0.8773
Epoch 1/1, Loss after 8720 samples: 0.1528
Epoch 1/1, Loss after 8928 samples: 0.1034
Epoch 1/1, Loss after 9136 samples: 0.1152
Average Loss on fact answering task after 9200 samples: 5.9093
Average Loss on fact answering task after 9200 samples: 6.0090
Average Loss on fact answering task after 9200 samples: 5.8563
Average Loss on fact answering task after 9200 samples: 6.1217
Average Loss on fact answering task after 9200 samples: 5.8535
Mean accuracy: 0.9290, std: 0.0057, lower bound: 0.9173, upper bound: 0.9402 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9200 samples: 0.9290
Epoch 1/1, Loss after 9344 samples: 0.1479
Epoch 1/1, Loss after 9552 samples: 0.1701
Average Loss on fact answering task after 9712 samples: 5.8659
Average Loss on fact answering task after 9712 samples: 5.8172
Average Loss on fact answering task after 9712 samples: 5.9557
Average Loss on fact answering task after 9712 samples: 5.7883
Average Loss on fact answering task after 9712 samples: 5.9923
Mean accuracy: 0.8917, std: 0.0073, lower bound: 0.8763, upper bound: 0.9052 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9712 samples: 0.8915
Epoch 1/1, Loss after 9760 samples: 0.2200
Epoch 1/1, Loss after 9968 samples: 0.1915
Epoch 1/1, Loss after 10176 samples: 0.1327
Average Loss on fact answering task after 10224 samples: 5.9767
Average Loss on fact answering task after 10224 samples: 6.2202
Average Loss on fact answering task after 10224 samples: 6.0389
Average Loss on fact answering task after 10224 samples: 5.9469
Average Loss on fact answering task after 10224 samples: 5.8176
Mean accuracy: 0.8702, std: 0.0077, lower bound: 0.8555, upper bound: 0.8854 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10224 samples: 0.8702
Epoch 1/1, Loss after 10384 samples: 0.1319
Epoch 1/1, Loss after 10592 samples: 0.1178
Average Loss on fact answering task after 10736 samples: 6.1354
Average Loss on fact answering task after 10736 samples: 6.0133
Average Loss on fact answering task after 10736 samples: 5.8557
Average Loss on fact answering task after 10736 samples: 5.9901
Average Loss on fact answering task after 10736 samples: 6.1274
Mean accuracy: 0.8968, std: 0.0069, lower bound: 0.8818, upper bound: 0.9102 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10736 samples: 0.8971
Epoch 1/1, Loss after 10800 samples: 0.1542
Epoch 1/1, Loss after 11008 samples: 0.1561
Epoch 1/1, Loss after 11216 samples: 0.1091
Average Loss on fact answering task after 11248 samples: 6.2441
Average Loss on fact answering task after 11248 samples: 6.0640
Average Loss on fact answering task after 11248 samples: 6.1767
Average Loss on fact answering task after 11248 samples: 6.0529
Average Loss on fact answering task after 11248 samples: 5.8467
Mean accuracy: 0.9260, std: 0.0057, lower bound: 0.9148, upper bound: 0.9371 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11248 samples: 0.9260
Epoch 1/1, Loss after 11424 samples: 0.1658
Epoch 1/1, Loss after 11632 samples: 0.1144
Average Loss on fact answering task after 11760 samples: 6.2087
Average Loss on fact answering task after 11760 samples: 6.1361
Average Loss on fact answering task after 11760 samples: 6.0861
Average Loss on fact answering task after 11760 samples: 6.0954
Average Loss on fact answering task after 11760 samples: 5.9133
Mean accuracy: 0.9070, std: 0.0065, lower bound: 0.8940, upper bound: 0.9199 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11760 samples: 0.9067
Epoch 1/1, Loss after 11840 samples: 0.1011
Epoch 1/1, Loss after 12048 samples: 0.1436
Epoch 1/1, Loss after 12256 samples: 0.1293
Average Loss on fact answering task after 12272 samples: 6.0238
Average Loss on fact answering task after 12272 samples: 5.9933
Average Loss on fact answering task after 12272 samples: 5.9585
Average Loss on fact answering task after 12272 samples: 6.0121
Average Loss on fact answering task after 12272 samples: 6.0634
Mean accuracy: 0.8347, std: 0.0081, lower bound: 0.8184, upper bound: 0.8509 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12272 samples: 0.8347
Epoch 1/1, Loss after 12464 samples: 0.1338
Epoch 1/1, Loss after 12672 samples: 0.1136
Average Loss on fact answering task after 12784 samples: 6.1629
Average Loss on fact answering task after 12784 samples: 5.9136
Average Loss on fact answering task after 12784 samples: 6.1767
Average Loss on fact answering task after 12784 samples: 6.0487
Average Loss on fact answering task after 12784 samples: 5.8642
Mean accuracy: 0.9101, std: 0.0066, lower bound: 0.8971, upper bound: 0.9224 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12784 samples: 0.9102
Epoch 1/1, Loss after 12880 samples: 0.1320
Epoch 1/1, Loss after 13088 samples: 0.1041
Epoch 1/1, Loss after 13296 samples: 0.1327
Average Loss on fact answering task after 13296 samples: 6.2113
Average Loss on fact answering task after 13296 samples: 6.2065
Average Loss on fact answering task after 13296 samples: 6.0862
Average Loss on fact answering task after 13296 samples: 5.9228
Average Loss on fact answering task after 13296 samples: 6.1812
Mean accuracy: 0.9054, std: 0.0066, lower bound: 0.8925, upper bound: 0.9173 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13296 samples: 0.9057
Epoch 1/1, Loss after 13504 samples: 0.0849
Epoch 1/1, Loss after 13712 samples: 0.1078
Average Loss on fact answering task after 13808 samples: 6.1595
Average Loss on fact answering task after 13808 samples: 5.9609
Average Loss on fact answering task after 13808 samples: 5.8442
Average Loss on fact answering task after 13808 samples: 6.2217
Average Loss on fact answering task after 13808 samples: 6.1566
Mean accuracy: 0.8691, std: 0.0073, lower bound: 0.8550, upper bound: 0.8834 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13808 samples: 0.8692
Epoch 1/1, Loss after 13920 samples: 0.0736
Epoch 1/1, Loss after 14128 samples: 0.1846
Average Loss on fact answering task after 14320 samples: 6.0151
Average Loss on fact answering task after 14320 samples: 6.1142
Average Loss on fact answering task after 14320 samples: 5.8697
Average Loss on fact answering task after 14320 samples: 6.2005
Average Loss on fact answering task after 14320 samples: 6.1559
Mean accuracy: 0.8921, std: 0.0068, lower bound: 0.8788, upper bound: 0.9057 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14320 samples: 0.8920
Epoch 1/1, Loss after 14336 samples: 0.1387
Epoch 1/1, Loss after 14544 samples: 0.1306
Epoch 1/1, Loss after 14752 samples: 0.1434
Average Loss on fact answering task after 14832 samples: 6.1355
Average Loss on fact answering task after 14832 samples: 6.0263
Average Loss on fact answering task after 14832 samples: 6.1164
Average Loss on fact answering task after 14832 samples: 5.9217
Average Loss on fact answering task after 14832 samples: 6.1218
Mean accuracy: 0.8805, std: 0.0073, lower bound: 0.8656, upper bound: 0.8950 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14832 samples: 0.8803
Epoch 1/1, Loss after 14960 samples: 0.0989
Epoch 1/1, Loss after 15168 samples: 0.1151
Average Loss on fact answering task after 15344 samples: 5.9569
Average Loss on fact answering task after 15344 samples: 6.0610
Average Loss on fact answering task after 15344 samples: 5.8897
Average Loss on fact answering task after 15344 samples: 6.1801
Average Loss on fact answering task after 15344 samples: 6.0383
Mean accuracy: 0.8735, std: 0.0075, lower bound: 0.8585, upper bound: 0.8889 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 15344 samples: 0.8737
Epoch 1/1, Loss after 15376 samples: 0.1686
Epoch 1/1, Loss after 15584 samples: 0.1513
Training signal is False, stopping training
Training finished
Best model: {'eval_acc': 0.9421906693711968, 'nb_samples': 7664}
Training loss logs: [{'samples': 192, 'loss': 0.7154411902794471}, {'samples': 400, 'loss': 0.7116417518028846}, {'samples': 608, 'loss': 0.6833067673903245}, {'samples': 816, 'loss': 0.6523144061748798}, {'samples': 1024, 'loss': 0.6108210637019231}, {'samples': 1232, 'loss': 0.5758963364821214}, {'samples': 1440, 'loss': 0.5350886124830979}, {'samples': 1648, 'loss': 0.472477546105018}, {'samples': 1856, 'loss': 0.5573297647329477}, {'samples': 2064, 'loss': 0.4795735799349271}, {'samples': 2272, 'loss': 0.3981205866887019}, {'samples': 2480, 'loss': 0.3491985614483173}, {'samples': 2688, 'loss': 0.3649863096383902}, {'samples': 2896, 'loss': 0.27267899880042445}, {'samples': 3104, 'loss': 0.33130271618182844}, {'samples': 3312, 'loss': 0.27435089074648344}, {'samples': 3520, 'loss': 0.3221089289738582}, {'samples': 3728, 'loss': 0.2431225868371817}, {'samples': 3936, 'loss': 0.26820435890784633}, {'samples': 4144, 'loss': 0.356229672065148}, {'samples': 4352, 'loss': 0.2907930795962994}, {'samples': 4560, 'loss': 0.18480577835669884}, {'samples': 4768, 'loss': 0.19515814230992243}, {'samples': 4976, 'loss': 0.2585742657001202}, {'samples': 5184, 'loss': 0.14758239342616156}, {'samples': 5392, 'loss': 0.24691637662740853}, {'samples': 5600, 'loss': 0.24009402898641732}, {'samples': 5808, 'loss': 0.2354313593644362}, {'samples': 6016, 'loss': 0.16756343841552734}, {'samples': 6224, 'loss': 0.20903864273658165}, {'samples': 6432, 'loss': 0.19302723957942083}, {'samples': 6640, 'loss': 0.14692916319920465}, {'samples': 6848, 'loss': 0.15170577397713295}, {'samples': 7056, 'loss': 0.1550635833006639}, {'samples': 7264, 'loss': 0.18982179348285383}, {'samples': 7472, 'loss': 0.18383557521379912}, {'samples': 7680, 'loss': 0.17206850418677697}, {'samples': 7888, 'loss': 0.2178334639622615}, {'samples': 8096, 'loss': 0.13689020046821007}, {'samples': 8304, 'loss': 0.14549335608115563}, {'samples': 8512, 'loss': 0.07145022887449998}, {'samples': 8720, 'loss': 0.15275510687094468}, {'samples': 8928, 'loss': 0.10344937672981849}, {'samples': 9136, 'loss': 0.11517469241068913}, {'samples': 9344, 'loss': 0.1479275501691378}, {'samples': 9552, 'loss': 0.17005723256331223}, {'samples': 9760, 'loss': 0.21997697536761945}, {'samples': 9968, 'loss': 0.1914673218360314}, {'samples': 10176, 'loss': 0.13269707331290612}, {'samples': 10384, 'loss': 0.13192661908956674}, {'samples': 10592, 'loss': 0.11782382772519039}, {'samples': 10800, 'loss': 0.15421373798297003}, {'samples': 11008, 'loss': 0.15611158884488618}, {'samples': 11216, 'loss': 0.10909037865125217}, {'samples': 11424, 'loss': 0.16575887111517099}, {'samples': 11632, 'loss': 0.11441275477409363}, {'samples': 11840, 'loss': 0.10108104577431312}, {'samples': 12048, 'loss': 0.14359202751746544}, {'samples': 12256, 'loss': 0.12926399020048288}, {'samples': 12464, 'loss': 0.13384093688084528}, {'samples': 12672, 'loss': 0.11364120015731224}, {'samples': 12880, 'loss': 0.13200436188624456}, {'samples': 13088, 'loss': 0.10414395194787246}, {'samples': 13296, 'loss': 0.1327469119658837}, {'samples': 13504, 'loss': 0.08493630931927608}, {'samples': 13712, 'loss': 0.10779402347711417}, {'samples': 13920, 'loss': 0.07355777575419499}, {'samples': 14128, 'loss': 0.1846420168876648}, {'samples': 14336, 'loss': 0.1387098993246372}, {'samples': 14544, 'loss': 0.13055730783022368}, {'samples': 14752, 'loss': 0.14337643063985384}, {'samples': 14960, 'loss': 0.09893007003344022}, {'samples': 15168, 'loss': 0.11509224543204674}, {'samples': 15376, 'loss': 0.16860678104253915}, {'samples': 15584, 'loss': 0.15129251892750079}]
Evaluation accuracy logs: [{'samples': 496, 'accuracy': 0.6010060851926977, 'std': 0.011163930375319445, 'lower_bound': 0.5790948275862069, 'upper_bound': 0.6232251521298174}, {'samples': 1008, 'accuracy': 0.7619371196754564, 'std': 0.009908083673150407, 'lower_bound': 0.7429006085192698, 'upper_bound': 0.7809330628803245}, {'samples': 1520, 'accuracy': 0.7946501014198784, 'std': 0.009293397088662463, 'lower_bound': 0.7758620689655172, 'upper_bound': 0.8118661257606491}, {'samples': 2032, 'accuracy': 0.8497322515212982, 'std': 0.007971247843715426, 'lower_bound': 0.8336713995943205, 'upper_bound': 0.8646044624746451}, {'samples': 2544, 'accuracy': 0.8535309330628804, 'std': 0.007946304597927237, 'lower_bound': 0.8377281947261663, 'upper_bound': 0.8686612576064908}, {'samples': 3056, 'accuracy': 0.8057302231237322, 'std': 0.009582407512090415, 'lower_bound': 0.7865111561866126, 'upper_bound': 0.8240491886409737}, {'samples': 3568, 'accuracy': 0.8729604462474645, 'std': 0.007215358203079108, 'lower_bound': 0.8585192697768763, 'upper_bound': 0.8864097363083164}, {'samples': 4080, 'accuracy': 0.9137398580121704, 'std': 0.00626443206978903, 'lower_bound': 0.9016227180527383, 'upper_bound': 0.9259634888438134}, {'samples': 4592, 'accuracy': 0.8010598377281947, 'std': 0.009272432664684988, 'lower_bound': 0.7824416835699797, 'upper_bound': 0.8189655172413793}, {'samples': 5104, 'accuracy': 0.8890273833671399, 'std': 0.0072505594476919314, 'lower_bound': 0.8737322515212982, 'upper_bound': 0.9026369168356998}, {'samples': 5616, 'accuracy': 0.9153879310344828, 'std': 0.006034865734348748, 'lower_bound': 0.904158215010142, 'upper_bound': 0.9274847870182555}, {'samples': 6128, 'accuracy': 0.9185207910750507, 'std': 0.00647426467485207, 'lower_bound': 0.9051724137931034, 'upper_bound': 0.930540060851927}, {'samples': 6640, 'accuracy': 0.834328093306288, 'std': 0.008382645522909116, 'lower_bound': 0.8179513184584178, 'upper_bound': 0.8509127789046653}, {'samples': 7152, 'accuracy': 0.9234741379310344, 'std': 0.006119803511512668, 'lower_bound': 0.9122591277890466, 'upper_bound': 0.9355983772819473}, {'samples': 7664, 'accuracy': 0.9419645030425964, 'std': 0.0052152672356338215, 'lower_bound': 0.9315415821501014, 'upper_bound': 0.951331135902637}, {'samples': 8176, 'accuracy': 0.908841784989858, 'std': 0.006574955828557058, 'lower_bound': 0.8960446247464503, 'upper_bound': 0.920892494929006}, {'samples': 8688, 'accuracy': 0.8772317444219067, 'std': 0.007675334153269567, 'lower_bound': 0.862563387423935, 'upper_bound': 0.8920005070993915}, {'samples': 9200, 'accuracy': 0.9290172413793102, 'std': 0.005729808364246132, 'lower_bound': 0.9173301217038539, 'upper_bound': 0.9401622718052738}, {'samples': 9712, 'accuracy': 0.8916769776876268, 'std': 0.00734550983147404, 'lower_bound': 0.8762550709939148, 'upper_bound': 0.9051724137931034}, {'samples': 10224, 'accuracy': 0.8701556795131846, 'std': 0.00765727118366975, 'lower_bound': 0.8554766734279919, 'upper_bound': 0.885408215010142}, {'samples': 10736, 'accuracy': 0.8968144016227181, 'std': 0.006917394750565991, 'lower_bound': 0.8818458417849898, 'upper_bound': 0.9102434077079108}, {'samples': 11248, 'accuracy': 0.9260096348884381, 'std': 0.005691334386277889, 'lower_bound': 0.9148073022312373, 'upper_bound': 0.9371196754563894}, {'samples': 11760, 'accuracy': 0.9069949290060851, 'std': 0.006529053130512293, 'lower_bound': 0.8940035496957404, 'upper_bound': 0.9198782961460447}, {'samples': 12272, 'accuracy': 0.8347074036511155, 'std': 0.008144135438870444, 'lower_bound': 0.8184330628803246, 'upper_bound': 0.8509127789046653}, {'samples': 12784, 'accuracy': 0.910119168356998, 'std': 0.0066001859236946405, 'lower_bound': 0.8970588235294118, 'upper_bound': 0.9224137931034483}, {'samples': 13296, 'accuracy': 0.9054426977687626, 'std': 0.006614740041361759, 'lower_bound': 0.8924949290060852, 'upper_bound': 0.9173427991886409}, {'samples': 13808, 'accuracy': 0.8691232251521298, 'std': 0.0072858567924859625, 'lower_bound': 0.8549695740365112, 'upper_bound': 0.8833671399594321}, {'samples': 14320, 'accuracy': 0.8921409736308317, 'std': 0.006815740221560972, 'lower_bound': 0.8787905679513184, 'upper_bound': 0.9056795131845842}, {'samples': 14832, 'accuracy': 0.8805121703853955, 'std': 0.007328158206722012, 'lower_bound': 0.8656186612576064, 'upper_bound': 0.8950304259634888}, {'samples': 15344, 'accuracy': 0.8735248478701826, 'std': 0.007531437003996587, 'lower_bound': 0.8585192697768763, 'upper_bound': 0.8889452332657201}]
