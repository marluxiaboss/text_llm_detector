{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (pipeline, BertTokenizer, BertForMaskedLM, BertConfig, DataCollatorForLanguageModeling,\n",
    "                            Trainer, TrainingArguments, RobertaTokenizer, RobertaForMaskedLM)\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict, concatenate_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.10731099545955658,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello i'm a fashion model.\"},\n",
       " {'score': 0.08774477988481522,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello i'm a role model.\"},\n",
       " {'score': 0.05338403955101967,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello i'm a new model.\"},\n",
       " {'score': 0.04667219892144203,\n",
       "  'token': 3565,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"hello i'm a super model.\"},\n",
       " {'score': 0.02709587849676609,\n",
       "  'token': 2986,\n",
       "  'token_str': 'fine',\n",
       "  'sequence': \"hello i'm a fine model.\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "\n",
    "unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9272459745407104,\n",
       "  'token': 2413,\n",
       "  'token_str': 'french',\n",
       "  'sequence': 'le journal de mickey is written in french.'},\n",
       " {'score': 0.013484428636729717,\n",
       "  'token': 2394,\n",
       "  'token_str': 'english',\n",
       "  'sequence': 'le journal de mickey is written in english.'},\n",
       " {'score': 0.012427841313183308,\n",
       "  'token': 16659,\n",
       "  'token_str': 'breton',\n",
       "  'sequence': 'le journal de mickey is written in breton.'},\n",
       " {'score': 0.004832481034100056,\n",
       "  'token': 13973,\n",
       "  'token_str': 'catalan',\n",
       "  'sequence': 'le journal de mickey is written in catalan.'},\n",
       " {'score': 0.0039960830472409725,\n",
       "  'token': 3000,\n",
       "  'token_str': 'paris',\n",
       "  'sequence': 'le journal de mickey is written in paris.'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Le Journal de Mickey is written in [MASK].\"\n",
    "unmasker(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForMaskedLM:\n\tMissing key(s) in state_dict: \"cls.predictions.bias\", \"cls.predictions.transform.dense.weight\", \"cls.predictions.transform.dense.bias\", \"cls.predictions.transform.LayerNorm.weight\", \"cls.predictions.transform.LayerNorm.bias\", \"cls.predictions.decoder.weight\", \"cls.predictions.decoder.bias\". \n\tUnexpected key(s) in state_dict: \"classifier.weight\", \"classifier.bias\", \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForMaskedLM(config)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForMaskedLM:\n\tMissing key(s) in state_dict: \"cls.predictions.bias\", \"cls.predictions.transform.dense.weight\", \"cls.predictions.transform.dense.bias\", \"cls.predictions.transform.LayerNorm.weight\", \"cls.predictions.transform.LayerNorm.bias\", \"cls.predictions.decoder.weight\", \"cls.predictions.decoder.bias\". \n\tUnexpected key(s) in state_dict: \"classifier.weight\", \"classifier.bias\", \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\". "
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "model_path = \"best_model.pt\"\n",
    "state_dict = torch.load(model_path)\n",
    "model = BertForMaskedLM(config)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c a t\n",
      "d o g\n",
      "b e a r\n",
      "m a n\n",
      "# # i e\n"
     ]
    }
   ],
   "source": [
    "text = \"The quick brown [MASK] jumps over the lazy dog.\"\n",
    "tokenized_text = text.split()\n",
    "tokenized_text[3] = '[MASK]'\n",
    "masked_text = ' '.join(tokenized_text)\n",
    "\n",
    "input = tokenizer.encode(masked_text, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "\n",
    "    print(tokenizer.decode(token))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define sentences for benchmarking\n",
    "sentences = [\"Hello I'm a [MASK] model.\", \"The quick brown [MASK] jumps over the lazy dog.\"]\n",
    "\n",
    "# Define the actual words that were masked\n",
    "actual_words = [\"language\", \"fox\"]\n",
    "\n",
    "# Initialize a list to store the model's predictions\n",
    "predicted_words = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    # Encode the sentence and get the position of the masked token\n",
    "    inputs = tokenizer.encode_plus(sentence, return_tensors='pt')\n",
    "    mask_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "\n",
    "    # Use the model to predict the masked token\n",
    "    outputs = model(**inputs)\n",
    "    predictions = outputs.logits[0, mask_index, :]\n",
    "\n",
    "    # Get the predicted token\n",
    "    predicted_token = torch.argmax(predictions)\n",
    "    predicted_word = tokenizer.decode([predicted_token])\n",
    "\n",
    "    # Add the predicted word to the list\n",
    "    predicted_words.append(predicted_word)\n",
    "\n",
    "# Calculate the accuracy of the model's predictions\n",
    "accuracy = accuracy_score(actual_words, predicted_words)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 3.7346343994140625\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define sentences for benchmarking\n",
    "sentences = [\"Hello I'm a [MASK] model.\", \"The quick brown [MASK] jumps over the lazy dog.\"]\n",
    "\n",
    "# Define the actual words that were masked\n",
    "actual_words = [\"language\", \"fox\"]\n",
    "\n",
    "# Initialize a list to store the losses\n",
    "losses = []\n",
    "\n",
    "for sentence, actual_word in zip(sentences, actual_words):\n",
    "    # Encode the sentence and get the position of the masked token\n",
    "    inputs = tokenizer.encode_plus(sentence, return_tensors='pt')\n",
    "    mask_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "\n",
    "    # Replace the masked token with the actual token\n",
    "    inputs[\"input_ids\"][0, mask_index] = tokenizer.encode(actual_word, add_special_tokens=False)[0]\n",
    "\n",
    "    # Use the model to calculate the loss\n",
    "    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "\n",
    "    # Add the loss to the list\n",
    "    losses.append(loss.item())\n",
    "\n",
    "# Calculate the average loss\n",
    "average_loss = sum(losses) / len(losses)\n",
    "\n",
    "print(f\"Average Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_dataset = load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_dataset[\"train\"][4][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(x, tokenizer):\n",
    "    return tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=200)\n",
    "\n",
    "wiki_dataset_tokenized = wiki_dataset.map( lambda x: tokenize_text(x, tokenizer), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 61\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (loss, outputs) \u001b[38;5;28;01mif\u001b[39;00m return_outputs \u001b[38;5;28;01melse\u001b[39;00m loss\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    def compute_loss(self, model, inputs, return_outputs=False):\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m        if self.label_smoother is not None and \"labels\" in inputs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m        return (loss, outputs) if return_outputs else loss\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TrainerWithCustomLoss(\n\u001b[0;32m---> 61\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m,\n\u001b[1;32m     62\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     63\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mwiki_dataset_tokenized[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     64\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# get loss on test set\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#trainer.train()\u001b[39;00m\n\u001b[1;32m     69\u001b[0m trainer\u001b[38;5;241m.\u001b[39mevaluate(wiki_dataset_tokenized[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    prediction_loss_only=True,\n",
    "    #label_names=[]\n",
    ")\n",
    "\n",
    "class TrainerWithCustomLoss(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        # if loss is nan, there is an issue with the labels, we return 0\n",
    "        if torch.isnan(loss):\n",
    "            loss = torch.tensor(0.0, requires_grad=True).to(loss.device)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \"\"\"\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        if self.label_smoother is not None and \"labels\" in inputs:\n",
    "            labels = inputs.pop(\"labels\")\n",
    "        else:\n",
    "            labels = None\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # code for calculating accuracy\n",
    "        if \"labels\" in inputs:\n",
    "            logits = outputs.logits.detach()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            acc1 = metric.compute(predictions=preds, references=inputs.labels)\n",
    "            self.log({'accuracy_score': acc1})\n",
    "            acc = (\n",
    "                (preds.argmax(axis=-1) == inputs.labels.reshape(1, len(inputs.labels))[0])\n",
    "                .type(torch.float)\n",
    "                .mean()\n",
    "                .item()\n",
    "            )\n",
    "            self.log({\"train_accuracy\": acc})\n",
    "        # end code for calculating accuracy\n",
    "                    \n",
    "        # Save past state if it exists\n",
    "        # TODO: this needs to be fixed and made cleaner later.\n",
    "        if self.args.past_index >= 0:\n",
    "            self._past = outputs[self.args.past_index]\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.label_smoother(outputs, labels)\n",
    "        else:\n",
    "            # We don't use .loss here since the model may return tuples instead of ModelOutput.\n",
    "            loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "trainer = TrainerWithCustomLoss(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=wiki_dataset_tokenized[\"test\"],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# get loss on test set\n",
    "#trainer.train()\n",
    "trainer.evaluate(wiki_dataset_tokenized[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('distilbert/distilbert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('distilbert/distilbert-base-uncased')\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "def tokenize_text(x, tokenizer):\n",
    "    return tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=200)\n",
    "\n",
    "wiki_dataset_tokenized = wiki_dataset.map( lambda x: tokenize_text(x, tokenizer), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [273/273 03:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 10.404870986938477,\n",
       " 'eval_runtime': 210.8167,\n",
       " 'eval_samples_per_second': 20.672,\n",
       " 'eval_steps_per_second': 1.295}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    prediction_loss_only=True,\n",
    "    #label_names=[]\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=wiki_dataset_tokenized[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "\n",
    ")\n",
    "\n",
    "# get loss on test set\n",
    "#trainer.train()\n",
    "trainer.evaluate(wiki_dataset_tokenized[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to make BERT degenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='1090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   6/1090 00:00 < 03:00, 6.02 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# get loss on test set\u001b[39;00m\n\u001b[1;32m     36\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 37\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwiki_dataset_tokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/trainer.py:3229\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3226\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3228\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3229\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3230\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3232\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3233\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3239\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/trainer.py:3450\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3447\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((labels))\n\u001b[1;32m   3448\u001b[0m     labels_host \u001b[38;5;241m=\u001b[39m labels \u001b[38;5;28;01mif\u001b[39;00m labels_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m nested_concat(labels_host, labels, padding_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m-> 3450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_prediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3452\u001b[0m \u001b[38;5;66;03m# Gather all tensors and put them back on the CPU if we have done enough accumulation steps.\u001b[39;00m\n\u001b[1;32m   3453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_accumulation_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39meval_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/trainer_callback.py:410\u001b[0m, in \u001b[0;36mCallbackHandler.on_prediction_step\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_prediction_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_prediction_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/trainer_callback.py:414\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/utils/notebook.py:322\u001b[0m, in \u001b[0;36mNotebookProgressCallback.on_prediction_step\u001b[0;34m(self, args, state, control, eval_dataloader, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_bar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_bar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/utils/notebook.py:161\u001b[0m, in \u001b[0;36mNotebookProgressBar.update\u001b[0;34m(self, value, force_update, comment)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_time_per_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicted_remaining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_time_per_item \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m-\u001b[39m value)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_bar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_value \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_time \u001b[38;5;241m=\u001b[39m current_time\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/utils/notebook.py:186\u001b[0m, in \u001b[0;36mNotebookProgressBar.update_bar\u001b[0;34m(self, value, comment)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_time_per_item\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m it/s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomment) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/utils/notebook.py:197\u001b[0m, in \u001b[0;36mNotebookProgressBar.display\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m disp\u001b[38;5;241m.\u001b[39mdisplay(disp\u001b[38;5;241m.\u001b[39mHTML(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhtml_code), display_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTML\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml_code\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/IPython/core/display_functions.py:374\u001b[0m, in \u001b[0;36mDisplayHandle.update\u001b[0;34m(self, obj, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update existing displays with my id\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m        additional keyword arguments passed to update_display\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m     \u001b[43mupdate_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/IPython/core/display_functions.py:326\u001b[0m, in \u001b[0;36mupdate_display\u001b[0;34m(obj, display_id, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update an existing display by id\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m:func:`display`\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    325\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/IPython/core/display_functions.py:305\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;66;03m# kwarg-specified metadata gets precedence\u001b[39;00m\n\u001b[1;32m    304\u001b[0m             _merge(md_dict, metadata)\n\u001b[0;32m--> 305\u001b[0m         \u001b[43mpublish_display_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmd_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_id:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisplayHandle(display_id)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/IPython/core/display_functions.py:93\u001b[0m, in \u001b[0;36mpublish_display_data\u001b[0;34m(data, metadata, source, transient, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transient:\n\u001b[1;32m     91\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransient\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transient\n\u001b[0;32m---> 93\u001b[0m \u001b[43mdisplay_pub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/ipykernel/zmqshell.py:103\u001b[0m, in \u001b[0;36mZMQDisplayPublisher.publish\u001b[0;34m(self, data, metadata, transient, update)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     83\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     87\u001b[0m ):\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Publish a display-data message\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m        If True, send an update_display_data message instead of display_data.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush_streams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/ipykernel/zmqshell.py:66\u001b[0m, in \u001b[0;36mZMQDisplayPublisher._flush_streams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flush_streams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/ipykernel/iostream.py:604\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"trigger actual zmq send\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03msend will happen in the background thread\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mthread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    602\u001b[0m ):\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;66;03m# request flush on the background thread\u001b[39;00m\n\u001b[0;32m--> 604\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[1;32m    606\u001b[0m     evt \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mEvent()\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/ipykernel/iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     f()\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/zmq/sugar/socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    689\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[1;32m    690\u001b[0m             data,\n\u001b[1;32m    691\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[1;32m    692\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    693\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[1;32m    694\u001b[0m         )\n\u001b[1;32m    695\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:243\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wiki_dataset = load_dataset('wikitext', 'wikitext-2-raw-v1')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "def tokenize_text(x, tokenizer):\n",
    "    return tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=200)\n",
    "\n",
    "wiki_dataset_tokenized = wiki_dataset.map( lambda x: tokenize_text(x, tokenizer), batched=True)\n",
    "\n",
    "\n",
    "# training with high lr\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-2,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "\n",
    "trainer = TrainerWithCustomLoss(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=wiki_dataset_tokenized[\"train\"].select(range(100)),\n",
    "    eval_dataset=wiki_dataset_tokenized[\"test\"],\n",
    "    data_collator=data_collator\n",
    "\n",
    ")\n",
    "\n",
    "# get loss on test set\n",
    "trainer.train()\n",
    "trainer.evaluate(wiki_dataset_tokenized[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
    "\n",
    "preds = unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      "Writing in Variety , Todd McCarthy said the cast ensemble \" could not be better \" ; he praised Spacey 's \" handling of innuendo , subtle sarcasm , and blunt talk \" and the way he imbued Lester with \" genuine feeling \" . Janet Maslin in The New York Times said Spacey was at his \" wittiest and most agile \" to date , and Roger Ebert of the Chicago Sun @-@ Times singled Spacey out for successfully portraying a man who \" does reckless and foolish things [ but who ] doesn 't deceive himself \" . Kevin Jackson of Sight & Sound said Spacey impressed in ways distinct from his previous performances , the most satisfying aspect being his portrayal of \" both sap and hero \" . Writing in Film Quarterly , Gary Hentzi praised the actors , but said that characters such as Carolyn and Col. Fitts were stereotypes . Hentzi accused Mendes and Ball of identifying too readily with Jane and Ricky , saying the latter was their \" fantasy figure \"  a teenaged boy who 's an absurdly wealthy artist able to \" finance [ his ] own projects \" . Hentzi said Angela was the most believable teenager , in particular with her \" painfully familiar \" attempts to \" live up to an unworthy image of herself \" . Maslin agreed that some characters were unoriginal , but said their detailed characterizations made them memorable . Kenneth Turan of the Los Angeles Times said the actors coped \" faultlessly \" with what were difficult roles ; he called Spacey 's performance \" the energy that drives the film \" , saying the actor commanded audience involvement despite Lester not always being sympathetic . \" Against considerable odds , we do like [ [MASK] characters ] , \" Turan concluded .\n",
      "Text: \n",
      "On June 26 , 2007 , Stone Sour released a special edition version of [MASK] album with six previously unreleased tracks and a bonus DVD . The DVD featured a full concert performance by the band from October 2006 in Moscow and the music videos for \" 30 / 30 @-@ 150 , \" \" Through Glass , \" and \" Sillyworld . \" When talking about the special edition , vocalist Taylor said , \" we really wanted to do something which was really cool , \" saying that this shows the band 's different musical elements and them in their live element , which he says \" people really gravitate towards . \" In addition to this , Stone Sour released a live album of their concert in Moscow exclusively on iTunes , entitled Live in Moscow .\n",
      "Text: \n",
      "The presented plots of image impedance , [MASK] and phase change correspond to a low @-@ pass prototype filter section . The prototype has a cut @-@ off frequency of c\n",
      "Text: \n",
      "On June 24 , 1571 , Spanish conquistador Miguel Lpez de Legazpi arrived from New Spain ( now Mexico ) , and then exercised rule of the Spanish city of Manila as a territory of New Spain with the [MASK] of a city council in what today is the district of Intramuros . Lpez de Legazpi had the local royalty executed or exiled , after the failure of the Tondo Conspiracy ; a plot wherein an alliance between Japanese merchants , Luzon 's Huangs with several Datus and Rajahs plus the Bruneian Empire would band together to execute the Spaniards and their Latin @-@ American mercenaries , and Visayan allies . At the conclusion of which , the victorious Spaniards made Manila the capital of the Spanish East Indies and of the Philippines , which the empire would control for the next three centuries , from 1565 to 1898 .\n",
      "Text: \n",
      "Currently , the film holds an 88 % score on Rotten Tomatoes based on 180 reviews , with an average rating of 8 @.@ 2 / 10 ; the critical consensus reads , \" Flawlessly cast and brimming with dark , acid wit , American Beauty is a smart , provocative high point of late ' 90s mainstream Hollywood film . \" Metacritic gives the film a score of 86 , based on 33 reviews , indicating \" universal [MASK] . \"\n",
      "Text: \n",
      "Mendes found that he still had to convince DreamWorks ' production executives to let him direct . He had already discussed the film with Jinks and Cohen , and felt they supported him . Ball was also keen ; having seen Cabaret , he was impressed with Mendes ' \" keen visual sense \" and thought he did not make obvious choices . Ball felt that Mendes liked to look under the story 's surface , a talent he felt would [MASK] a good fit with the themes of American Beauty . Mendes ' background also reassured him , because of the prominent role the playwright usually has in a theater production . Over two meetings  the first with Cooper , Walter Parkes , and Laurie MacDonald , the second with Cooper alone  Mendes pitched himself to the studio . The studio soon approached Mendes with a deal to direct for the minimum salary allowed under Directors Guild of America rules  $ 150 @,@ 000 . Mendes accepted , and later recalled that after taxes and his agent 's commission , he only earned $ 38 @,@ 000 . In June 1998 , DreamWorks confirmed that it had contracted Mendes to direct the film .\n",
      "Text: \n",
      "Operation Torch , the Allied invasion of French North Africa in November 1942 , was coordinated from the \" Rock \" . General Dwight D. Eisenhower , who was given command of the operation , set up his headquarters in Gibraltar during the planning phases of the operation . Following the successful [MASK] of the North African campaign and the surrender of Italy in 1943 , Gibraltar 's role shifted from a forward operating base to a rear @-@ area supply position . The harbour continued to operate dry docks and supply depots for the convoy routes through the Mediterranean until V @-@ E Day in 1945 .\n",
      "Text: \n",
      "Externally , Stevens is always calm , but internally he is far from it . \" I 'm not as calm as everybody [MASK] , \" Stevens says . His wife Tracy adds , \" He  s calm and collected , but he  s fiercely competitive . He  s always thinking about how he can beat you . \" Former player Joel Cornette says \" Everyone sees Brad as a level @-@ headed , calm and cool coach , but he  s about as competitive of a guy as I know . We would get into it constantly , whether playing two @-@ on @-@ two or arguing about players  having better college careers . \"\n",
      "Text: \n",
      "On the outbreak of World War I in 1914 , Fabian Ware , a director of the Rio Tinto Company , found that at 45 years old he was too old to join the British Army . He used the influence of Rio Tinto chairman , Viscount Milner , to become the commander of a mobile unit of the British Red Cross . He arrived in France in September 1914 and whilst there was struck by the lack of any official mechanism for documenting or marking the location of graves of those who had been killed and felt compelled to create an organisation within the Red Cross for this purpose . In March 1915 , with the support of Nevil Macready , Adjutant @-@ General of the British Expeditionary Force , Ware 's work was given official recognition and support by the Imperial War Office and the unit was transferred to the British [MASK] as the Graves Registration Commission . The new Graves Registration Commission had over 31 @,@ 000 graves of British and Imperial soldiers registered by October 1915 and 50 @,@ 000 registered by May 1916 .\n",
      "Text: \n",
      "The origins of the hurricane were from a tropical wave that possibly spawned a tropical depression on August 27 , although there was minimal data over the next few days as it tracked to the west @-@ northwest . On August 31 , a nearby ship reported gale force winds , which indicated that a tropical storm had developed to the east @-@ northeast of the Lesser Antilles . Based on continuity , it is estimated the storm attained hurricane status later that day . Moving quickly to the west @-@ northwest , the storm passed north of the Lesser Antilles and Puerto Rico . Early on September 2 , a ship called the Gulfwing reported a barometric pressure of 978 mbar ( 28 @.@ 88 inHg ) , which confirmed that the storm attained hurricane status . After passing north of the Turks and Caicos islands , the hurricane struck Eleuthera and Harbour Island in the Bahamas on September 3 , the latter at 1100 UTC . A station on the latter island reported a pressure of 27 @.@ 90 inHg ( 945 mb ) during the 30 minute passage of the eye . Based on the pressure and the small size of the storm , it is estimated the hurricane struck Harbour Island with [MASK] winds of 140 mph ( 225 km / h ) , making it the equivalent of a modern Category 4 hurricane on the Saffir @-@ Simpson scale . Interpolation suggested that the storm reached major hurricane status , or Category 3 status , on September 2 .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "wiki_dataset = load_dataset('wikitext', 'wikitext-2-raw-v1')\n",
    "test_text = wiki_dataset[\"test\"][\"text\"]\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# discard empty text and with less than 100 characters\n",
    "test_text = [t for t in test_text if len(t) > 100]\n",
    "\n",
    "# sample 100 texts\n",
    "test_text = np.random.choice(test_text, 100)\n",
    "\n",
    "# mask 1 word in each text\n",
    "mask_indices = [np.random.randint(0, len(t.split())) for t in test_text]\n",
    "\n",
    "\n",
    "# mask the tokens\n",
    "masked_text = []\n",
    "for i, t in enumerate(test_text):\n",
    "    tokenized_text = t.split()\n",
    "    tokenized_text[mask_indices[i]] = '[MASK]'\n",
    "    masked_text.append(' '.join(tokenized_text))\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Text: \")\n",
    "    print(masked_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['input_ids'] shape:  torch.Size([1, 354])\n",
      "labels shape:  torch.Size([1, 354])\n",
      "ref_text:   Writing in Variety , Todd McCarthy said the cast ensemble \" could not be better \" ; he praised Spacey 's \" handling of innuendo , subtle sarcasm , and blunt talk \" and the way he imbued Lester with \" genuine feeling \" . Janet Maslin in The New York Times said Spacey was at his \" wittiest and most agile \" to date , and Roger Ebert of the Chicago Sun @-@ Times singled Spacey out for successfully portraying a man who \" does reckless and foolish things [ but who ] doesn 't deceive himself \" . Kevin Jackson of Sight & Sound said Spacey impressed in ways distinct from his previous performances , the most satisfying aspect being his portrayal of \" both sap and hero \" . Writing in Film Quarterly , Gary Hentzi praised the actors , but said that characters such as Carolyn and Col. Fitts were stereotypes . Hentzi accused Mendes and Ball of identifying too readily with Jane and Ricky , saying the latter was their \" fantasy figure \"  a teenaged boy who 's an absurdly wealthy artist able to \" finance [ his ] own projects \" . Hentzi said Angela was the most believable teenager , in particular with her \" painfully familiar \" attempts to \" live up to an unworthy image of herself \" . Maslin agreed that some characters were unoriginal , but said their detailed characterizations made them memorable . Kenneth Turan of the Los Angeles Times said the actors coped \" faultlessly \" with what were difficult roles ; he called Spacey 's performance \" the energy that drives the film \" , saying the actor commanded audience involvement despite Lester not always being sympathetic . \" Against considerable odds , we do like [ these characters ] , \" Turan concluded . \n",
      "\n",
      "masked_text:  Writing in Variety , Todd McCarthy said the cast ensemble \" could not be better \" ; he praised Spacey 's \" handling of innuendo , subtle sarcasm , and blunt talk \" and the way he imbued Lester with \" genuine feeling \" . Janet Maslin in The New York Times said Spacey was at his \" wittiest and most agile \" to date , and Roger Ebert of the Chicago Sun @-@ Times singled Spacey out for successfully portraying a man who \" does reckless and foolish things [ but who ] doesn 't deceive himself \" . Kevin Jackson of Sight & Sound said Spacey impressed in ways distinct from his previous performances , the most satisfying aspect being his portrayal of \" both sap and hero \" . Writing in Film Quarterly , Gary Hentzi praised the actors , but said that characters such as Carolyn and Col. Fitts were stereotypes . Hentzi accused Mendes and Ball of identifying too readily with Jane and Ricky , saying the latter was their \" fantasy figure \"  a teenaged boy who 's an absurdly wealthy artist able to \" finance [ his ] own projects \" . Hentzi said Angela was the most believable teenager , in particular with her \" painfully familiar \" attempts to \" live up to an unworthy image of herself \" . Maslin agreed that some characters were unoriginal , but said their detailed characterizations made them memorable . Kenneth Turan of the Los Angeles Times said the actors coped \" faultlessly \" with what were difficult roles ; he called Spacey 's performance \" the energy that drives the film \" , saying the actor commanded audience involvement despite Lester not always being sympathetic . \" Against considerable odds , we do like [ [MASK] characters ] , \" Turan concluded .\n",
      "len(masked_text.split()):  311\n",
      "len(ref_text.split()):  311\n",
      "Masked text:  Writing in Variety , Todd McCarthy said the cast ensemble \" could not be better \" ; he praised Spacey 's \" handling of innuendo , subtle sarcasm , and blunt talk \" and the way he imbued Lester with \" genuine feeling \" . Janet Maslin in The New York Times said Spacey was at his \" wittiest and most agile \" to date , and Roger Ebert of the Chicago Sun @-@ Times singled Spacey out for successfully portraying a man who \" does reckless and foolish things [ but who ] doesn 't deceive himself \" . Kevin Jackson of Sight & Sound said Spacey impressed in ways distinct from his previous performances , the most satisfying aspect being his portrayal of \" both sap and hero \" . Writing in Film Quarterly , Gary Hentzi praised the actors , but said that characters such as Carolyn and Col. Fitts were stereotypes . Hentzi accused Mendes and Ball of identifying too readily with Jane and Ricky , saying the latter was their \" fantasy figure \"  a teenaged boy who 's an absurdly wealthy artist able to \" finance [ his ] own projects \" . Hentzi said Angela was the most believable teenager , in particular with her \" painfully familiar \" attempts to \" live up to an unworthy image of herself \" . Maslin agreed that some characters were unoriginal , but said their detailed characterizations made them memorable . Kenneth Turan of the Los Angeles Times said the actors coped \" faultlessly \" with what were difficult roles ; he called Spacey 's performance \" the energy that drives the film \" , saying the actor commanded audience involvement despite Lester not always being sympathetic . \" Against considerable odds , we do like [ [MASK] characters ] , \" Turan concluded .\n",
      "Top 5 predictions:  previous past prior previously earlier\n",
      "Actual word:  these\n",
      "\n",
      "inputs['input_ids'] shape:  torch.Size([1, 148])\n",
      "labels shape:  torch.Size([1, 148])\n",
      "ref_text:   On June 26 , 2007 , Stone Sour released a special edition version of the album with six previously unreleased tracks and a bonus DVD . The DVD featured a full concert performance by the band from October 2006 in Moscow and the music videos for \" 30 / 30 @-@ 150 , \" \" Through Glass , \" and \" Sillyworld . \" When talking about the special edition , vocalist Taylor said , \" we really wanted to do something which was really cool , \" saying that this shows the band 's different musical elements and them in their live element , which he says \" people really gravitate towards . \" In addition to this , Stone Sour released a live album of their concert in Moscow exclusively on iTunes , entitled Live in Moscow . \n",
      "\n",
      "masked_text:  On June 26 , 2007 , Stone Sour released a special edition version of [MASK] album with six previously unreleased tracks and a bonus DVD . The DVD featured a full concert performance by the band from October 2006 in Moscow and the music videos for \" 30 / 30 @-@ 150 , \" \" Through Glass , \" and \" Sillyworld . \" When talking about the special edition , vocalist Taylor said , \" we really wanted to do something which was really cool , \" saying that this shows the band 's different musical elements and them in their live element , which he says \" people really gravitate towards . \" In addition to this , Stone Sour released a live album of their concert in Moscow exclusively on iTunes , entitled Live in Moscow .\n",
      "len(masked_text.split()):  140\n",
      "len(ref_text.split()):  140\n",
      "Masked text:  On June 26 , 2007 , Stone Sour released a special edition version of [MASK] album with six previously unreleased tracks and a bonus DVD . The DVD featured a full concert performance by the band from October 2006 in Moscow and the music videos for \" 30 / 30 @-@ 150 , \" \" Through Glass , \" and \" Sillyworld . \" When talking about the special edition , vocalist Taylor said , \" we really wanted to do something which was really cool , \" saying that this shows the band 's different musical elements and them in their live element , which he says \" people really gravitate towards . \" In addition to this , Stone Sour released a live album of their concert in Moscow exclusively on iTunes , entitled Live in Moscow .\n",
      "Top 5 predictions:  album dvd ep record edition\n",
      "Actual word:  the\n",
      "\n",
      "inputs['input_ids'] shape:  torch.Size([1, 39])\n",
      "labels shape:  torch.Size([1, 41])\n",
      "ref_text:   The presented plots of image impedance , attenuation and phase change correspond to a low @-@ pass prototype filter section . The prototype has a cut @-@ off frequency of c \n",
      "\n",
      "masked_text:  The presented plots of image impedance , [MASK] and phase change correspond to a low @-@ pass prototype filter section . The prototype has a cut @-@ off frequency of c\n",
      "len(masked_text.split()):  31\n",
      "len(ref_text.split()):  31\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (39) must match the size of tensor b (41) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen(masked_text.split()): \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(masked_text\u001b[38;5;241m.\u001b[39msplit()))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen(ref_text.split()): \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ref_text\u001b[38;5;241m.\u001b[39msplit()))\n\u001b[0;32m---> 28\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#mask_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reference_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, labels\u001b[38;5;241m=\u001b[39mlabels)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (39) must match the size of tensor b (41) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# compute loss with reference model on sampled texts\n",
    "losses = []\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "reference_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "reference_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, ref_text in enumerate(test_text):\n",
    "\n",
    "        # mask a word in the text randomly\n",
    "        masked_text = ref_text.split()\n",
    "        masked_text[mask_indices[i]] = '[MASK]'\n",
    "        masked_text = ' '.join(masked_text)\n",
    "\n",
    "        inputs = tokenizer(masked_text, return_tensors='pt')\n",
    "\n",
    "        #masked_token_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "\n",
    "        # see example in: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForMaskedLM\n",
    "\n",
    "        print(\"inputs['input_ids'] shape: \", inputs[\"input_ids\"].shape)\n",
    "\n",
    "        labels = tokenizer(ref_text, return_tensors='pt')[\"input_ids\"]\n",
    "        print(\"labels shape: \", labels.shape)\n",
    "        print(\"ref_text: \", ref_text)\n",
    "        print(\"masked_text: \", masked_text)\n",
    "        print(\"len(masked_text.split()): \", len(masked_text.split()))\n",
    "        print(\"len(ref_text.split()): \", len(ref_text.split()))\n",
    "        labels = torch.where(inputs.input_ids == tokenizer.mask_token_id, labels, -100)\n",
    "\n",
    "\n",
    "        #mask_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "\n",
    "        outputs = reference_model(**inputs, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        top_5_preds = torch.topk(logits[0, mask_index, :], 5, dim=1).indices[0].tolist()\n",
    "\n",
    "        print(\"Masked text: \", masked_text)\n",
    "        print(\"Top 5 predictions: \", tokenizer.decode(top_5_preds))\n",
    "        print(\"Actual word: \", ref_text.split()[mask_indices[i]])\n",
    "        print(\"\")\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "print(f\"Average Loss: {sum(losses) / len(losses)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# retrieve index of [MASK]\n",
    "mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "\n",
    "predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "tokenizer.decode(predicted_token_id)\n",
    "\n",
    "labels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "# mask labels of non-[MASK] tokens\n",
    "labels = torch.where(inputs.input_ids == tokenizer.mask_token_id, labels, -100)\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "round(outputs.loss.item(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run 1: loss = 0.65\n",
    "- run 2: loss = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 10.491268739700317\n"
     ]
    }
   ],
   "source": [
    "# compute loss with reference model on sampled texts\n",
    "losses = []\n",
    "\n",
    "# use distilbert as a placeholder for the finetuned_model\n",
    "tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "finetuned_model = BertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
    "finetuned_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, t in enumerate(masked_text):\n",
    "        inputs = tokenizer.encode_plus(t, return_tensors='pt')\n",
    "        mask_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "\n",
    "        outputs = finetuned_model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "print(f\"Average Loss: {sum(losses) / len(losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run 1: loss = 10.49\n",
    "- run 2: loss = 10.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.6526461672782898\n"
     ]
    }
   ],
   "source": [
    "wiki_dataset = load_dataset('wikitext', 'wikitext-2-raw-v1')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "def tokenize_text(x, tokenizer):\n",
    "    return tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=200)\n",
    "\n",
    "wiki_dataset_tokenized = wiki_dataset.map( lambda x: tokenize_text(x, tokenizer), batched=True)\n",
    "\n",
    "\n",
    "# training with high lr\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-2,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "\n",
    "trainer = TrainerWithCustomLoss(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=wiki_dataset_tokenized[\"train\"].select(range(100)),\n",
    "    eval_dataset=wiki_dataset_tokenized[\"test\"],\n",
    "    data_collator=data_collator\n",
    "\n",
    ")\n",
    "\n",
    "# compute loss with reference model on sampled texts\n",
    "losses = []\n",
    "\n",
    "# use distilbert as a placeholder for the finetuned_model\n",
    "finetuned_model = model\n",
    "finetuned_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, t in enumerate(masked_text):\n",
    "        inputs = tokenizer.encode_plus(t, return_tensors='pt').to(finetuned_model.device)\n",
    "        mask_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "\n",
    "        outputs = finetuned_model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "print(f\"Average Loss: {sum(losses) / len(losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with fact completion dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert and Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "reference_model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28018ae4630540ff9a651d9c8935289a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|| 2.09M/2.09M [00:01<00:00, 1.58MB/s]\n",
      "Downloading data: 100%|| 1.72M/1.72M [00:01<00:00, 1.47MB/s]\n",
      "Downloading data: 100%|| 639k/639k [00:00<00:00, 662kB/s]\n",
      "Downloading data: 100%|| 857k/857k [00:01<00:00, 770kB/s]\n",
      "Downloading data: 100%|| 1.97M/1.97M [00:01<00:00, 1.56MB/s]\n",
      "Downloading data: 100%|| 1.96M/1.96M [00:01<00:00, 1.65MB/s]\n",
      "Downloading data: 100%|| 2.12M/2.12M [00:02<00:00, 897kB/s]\n",
      "Downloading data: 100%|| 1.71M/1.71M [00:01<00:00, 1.45MB/s]\n",
      "Downloading data: 100%|| 1.36M/1.36M [00:01<00:00, 1.17MB/s]\n",
      "Downloading data: 100%|| 414k/414k [00:01<00:00, 412kB/s]\n",
      "Downloading data: 100%|| 1.86M/1.86M [00:01<00:00, 1.44MB/s]\n",
      "Downloading data: 100%|| 871k/871k [00:01<00:00, 791kB/s]\n",
      "Downloading data: 100%|| 2.10M/2.10M [00:01<00:00, 1.70MB/s]\n",
      "Downloading data: 100%|| 1.55M/1.55M [00:01<00:00, 1.28MB/s]\n",
      "Downloading data: 100%|| 309k/309k [00:00<00:00, 322kB/s]\n",
      "Downloading data: 100%|| 565k/565k [00:00<00:00, 567kB/s]\n",
      "Downloading data: 100%|| 701k/701k [00:01<00:00, 674kB/s]\n",
      "Downloading data: 100%|| 1.67M/1.67M [00:01<00:00, 1.44MB/s]\n",
      "Downloading data: 100%|| 1.81M/1.81M [00:01<00:00, 1.54MB/s]\n",
      "Downloading data: 100%|| 827k/827k [00:01<00:00, 772kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cf7f39724f4517aa37463c1c3a552b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Bulgarian split:   0%|          | 0/20577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2590346c9e1b48f6bebcbc1bef016fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Catalan split:   0%|          | 0/18898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffb42ce77f64a0c8a0fca69ef1060b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Croatian split:   0%|          | 0/7358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336263cc4a6e45ecb4416b43ad3b1772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Czech split:   0%|          | 0/9427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca9f5c073e6439984d0309d6024dcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Danish split:   0%|          | 0/23365 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07dec5a5fd949198b154d2162bde81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Dutch split:   0%|          | 0/22590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c4db25cb5a4fc9b5f678156a7a5215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating English split:   0%|          | 0/26254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf50d274b1c49b1b4a541efd7035489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating French split:   0%|          | 0/18395 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2a270c6ed042daac6aad76a5bd7247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating German split:   0%|          | 0/16287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224bef4c0c8e44e29f316a31ea6e0159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Hungarian split:   0%|          | 0/4650 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c081f14d9cb4c9ab408946551e4fbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Italian split:   0%|          | 0/20448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e2addeb85c4185919c5a08729a7de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Polish split:   0%|          | 0/9484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1620ab840414c99a45f498b9bdd8006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Portuguese split:   0%|          | 0/22974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e425d40311744e09b7dc39268f35948a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Romanian split:   0%|          | 0/17568 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df649948192482c832401c8603bac9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Russian split:   0%|          | 0/3289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dce0a7351234516b510f180ce4b60be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Serbian split:   0%|          | 0/5426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85a42c79d7c4a6b8b6d663755a0701e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Slovenian split:   0%|          | 0/7873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050cf60fae3f48e1a24d2469bd826265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Spanish split:   0%|          | 0/18786 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76639de3dae247289c923fc26ceb8dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Swedish split:   0%|          | 0/21576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a103ed17aed4958bc5a672e6c0f7855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Ukrainian split:   0%|          | 0/7918 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fact_completion_dataset = load_dataset('Polyglot-or-Not/Fact-Completion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dataset_id', 'stem', 'true', 'false', 'relation', 'subject', 'object'],\n",
       "    num_rows: 26254\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_completion_dataset[\"English\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b9bfaec22148b5a7472e5e91a44eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/26254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 4265 questions out of 26254\n",
      "Question: \n",
      "National City Corp.'s headquarters are in [MASK].\n",
      "Answer: \n",
      "Cleveland\n",
      "Question: \n",
      "Suriname shares a border with [MASK].\n",
      "Answer: \n",
      "Brazil\n",
      "Question: \n",
      "The headquarter of Amirkabir University of Technology is in [MASK].\n",
      "Answer: \n",
      "Tehran\n",
      "Question: \n",
      "County of London is within [MASK].\n",
      "Answer: \n",
      "England\n",
      "Question: \n",
      "Haji Mastan passed away in [MASK].\n",
      "Answer: \n",
      "Bombay\n",
      "Question: \n",
      "Tampines Expressway is located in [MASK].\n",
      "Answer: \n",
      "Singapore\n",
      "Question: \n",
      "Simeulue, in [MASK].\n",
      "Answer: \n",
      "Indonesia\n",
      "Question: \n",
      "Clare Balding is employed by [MASK].\n",
      "Answer: \n",
      "BBC\n",
      "Question: \n",
      "Neny Island is a part of the continent of [MASK].\n",
      "Answer: \n",
      "Antarctica\n",
      "Question: \n",
      "Sydney Sports Ground, located in [MASK].\n",
      "Answer: \n",
      "Australia\n"
     ]
    }
   ],
   "source": [
    "fact_completion_dataset = load_dataset('Polyglot-or-Not/Fact-Completion')[\"English\"]\n",
    "\n",
    "# filter out questions where the answer is not a single word for the tokenizer\n",
    "len_before = len(fact_completion_dataset)\n",
    "#fact_completion_dataset = fact_completion_dataset.filter(lambda x: len(x[\"true\"].split()) == 1)\n",
    "fact_completion_dataset = fact_completion_dataset.filter(lambda x: len(tokenizer(x[\"true\"]).input_ids) == 3)\n",
    "len_after = len(fact_completion_dataset)\n",
    "print(f\"Filtered out {len_before - len_after} questions out of {len_before}\")\n",
    "\n",
    "# take 100 random samples from the dataset\n",
    "fact_completion_dataset = fact_completion_dataset.shuffle(seed=42)\n",
    "fact_completion_dataset = fact_completion_dataset.select(range(100))\n",
    "questions = fact_completion_dataset[\"stem\"]\n",
    "answers = fact_completion_dataset[\"true\"]\n",
    "\n",
    "# add [MASK] at the end of each question\n",
    "# we also add a \".\", this is very important for bert models\n",
    "questions_masked = [q + \" [MASK].\" for q in questions]\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Question: \")\n",
    "    print(questions_masked[i])\n",
    "    print(\"Answer: \")\n",
    "    print(answers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  National City Corp.'s headquarters are in [MASK].\n",
      "Top 5 predictions:  washington chicago indianapolis seattle minneapolis\n",
      "Actual answer:  Cleveland\n",
      "loss:  5.181588172912598\n",
      "\n",
      "question:  Suriname shares a border with [MASK].\n",
      "Top 5 predictions:  guyana brazil belgium canada venezuela\n",
      "Actual answer:  Brazil\n",
      "loss:  2.2300407886505127\n",
      "\n",
      "question:  The headquarter of Amirkabir University of Technology is in [MASK].\n",
      "Top 5 predictions:  hyderabad tehran delhi chennai lucknow\n",
      "Actual answer:  Tehran\n",
      "loss:  2.6782381534576416\n",
      "\n",
      "question:  County of London is within [MASK].\n",
      "Top 5 predictions:  it westminster surrey london middlesex\n",
      "Actual answer:  England\n",
      "loss:  4.448187828063965\n",
      "\n",
      "question:  Haji Mastan passed away in [MASK].\n",
      "Top 5 predictions:  infancy december november september childhood\n",
      "Actual answer:  Bombay\n",
      "loss:  5.552617073059082\n",
      "\n",
      "question:  Tampines Expressway is located in [MASK].\n",
      "Top 5 predictions:  singapore bangkok thailand taiwan jakarta\n",
      "Actual answer:  Singapore\n",
      "loss:  0.5493001341819763\n",
      "\n",
      "question:  Simeulue, in [MASK].\n",
      "Top 5 predictions:  ##v romanian pressfu\n",
      "Actual answer:  Indonesia\n",
      "loss:  9.264809608459473\n",
      "\n",
      "question:  Clare Balding is employed by [MASK].\n",
      "Top 5 predictions:  him hon mt her ibm\n",
      "Actual answer:  BBC\n",
      "loss:  5.455806732177734\n",
      "\n",
      "question:  Neny Island is a part of the continent of [MASK].\n",
      "Top 5 predictions:  antarctica africa australia jamaica canada\n",
      "Actual answer:  Antarctica\n",
      "loss:  1.8163551092147827\n",
      "\n",
      "question:  Sydney Sports Ground, located in [MASK].\n",
      "Top 5 predictions:  mt sydney newtown parramatta central\n",
      "Actual answer:  Australia\n",
      "loss:  5.655631065368652\n",
      "\n",
      "question:  The native language of Omar Sy is [MASK].\n",
      "Top 5 predictions:  arabic somali french creole english\n",
      "Actual answer:  French\n",
      "loss:  2.797451972961426\n",
      "\n",
      "question:  Duchy of Brabant belongs to the continent of [MASK].\n",
      "Top 5 predictions:  europe france africa belgium germany\n",
      "Actual answer:  Europe\n",
      "loss:  0.034344032406806946\n",
      "\n",
      "question:  The original language of Mercure is [MASK].\n",
      "Top 5 predictions:  french english spanish breton german\n",
      "Actual answer:  French\n",
      "loss:  0.4321616291999817\n",
      "\n",
      "question:  TV Now was developed in [MASK].\n",
      "Top 5 predictions:  japan france germany australia china\n",
      "Actual answer:  Ireland\n",
      "loss:  4.903589725494385\n",
      "\n",
      "question:  Michaela Pereira is employed by [MASK].\n",
      "Top 5 predictions:  ibm amazon him microsoft sony\n",
      "Actual answer:  CNN\n",
      "loss:  6.660826683044434\n",
      "\n",
      "question:  Madeleine Robinson speaks [MASK].\n",
      "Top 5 predictions:  english french spanish up italian\n",
      "Actual answer:  French\n",
      "loss:  2.171632766723633\n",
      "\n",
      "question:  OpenVMS is developed by [MASK].\n",
      "Top 5 predictions:  microsoft ibm google intel mit\n",
      "Actual answer:  HP\n",
      "loss:  5.847489833831787\n",
      "\n",
      "question:  Alexander Knaifel performs [MASK].\n",
      "Top 5 predictions:  regularly here piano solo there\n",
      "Actual answer:  opera\n",
      "loss:  7.067992687225342\n",
      "\n",
      "question:  Leslie Halliwell originates from [MASK].\n",
      "Top 5 predictions:  london england australia scotland ireland\n",
      "Actual answer:  Bolton\n",
      "loss:  8.169981002807617\n",
      "\n",
      "question:  Nadia Boulanger writes in [MASK].\n",
      "Top 5 predictions:  french english russian france paris\n",
      "Actual answer:  French\n",
      "loss:  0.10304076969623566\n",
      "\n",
      "question:  Alice in Chains was founded in [MASK].\n",
      "Top 5 predictions:  chicago london texas canada california\n",
      "Actual answer:  Seattle\n",
      "loss:  5.256369590759277\n",
      "\n",
      "question:  Serena-Maneesh was formed in [MASK].\n",
      "Top 5 predictions:  ca japan france c london\n",
      "Actual answer:  Oslo\n",
      "loss:  5.952237129211426\n",
      "\n",
      "question:  Corinne Drewery was originally from [MASK].\n",
      "Top 5 predictions:  canada france ireland australia chicago\n",
      "Actual answer:  Nottingham\n",
      "loss:  8.250076293945312\n",
      "\n",
      "question:  Piero Fassino's position is [MASK].\n",
      "Top 5 predictions:  prop right unknown forward midfielder\n",
      "Actual answer:  mayor\n",
      "loss:  10.25523853302002\n",
      "\n",
      "question:  Pavel Datsyuk, the [MASK].\n",
      "Top 5 predictions:  mayor historian architect engineer painter\n",
      "Actual answer:  hockey\n",
      "loss:  13.00588607788086\n",
      "\n",
      "question:  Marion Post Wolcott, who works as [MASK].\n",
      "Top 5 predictions:  nurse housekeeper secretary receptionist mrs\n",
      "Actual answer:  photographer\n",
      "loss:  4.682371139526367\n",
      "\n",
      "question:  Kayunga District, which is located in [MASK].\n",
      "Top 5 predictions:  mt uganda nigeria myanmar dr\n",
      "Actual answer:  Uganda\n",
      "loss:  4.73405122756958\n",
      "\n",
      "question:  Massachusetts Mutual Life Insurance Company was created in [MASK].\n",
      "Top 5 predictions:  massachusetts boston england connecticut philadelphia\n",
      "Actual answer:  Springfield\n",
      "loss:  7.175625801086426\n",
      "\n",
      "question:  Landmark Records performs [MASK].\n",
      "Top 5 predictions:  here regularly live there worldwide\n",
      "Actual answer:  jazz\n",
      "loss:  3.9231696128845215\n",
      "\n",
      "question:  Lizzie McGuire performs [MASK].\n",
      "Top 5 predictions:  here there live regularly twice\n",
      "Actual answer:  sitcom\n",
      "loss:  13.15234375\n",
      "\n",
      "question:  Degrassi High, formulated in [MASK].\n",
      "Top 5 predictions:  canada toronto ca california calgary\n",
      "Actual answer:  Canada\n",
      "loss:  0.8687662482261658\n",
      "\n",
      "question:  IELTS is written in [MASK].\n",
      "Top 5 predictions:  english latin french german greek\n",
      "Actual answer:  English\n",
      "loss:  1.6023414134979248\n",
      "\n",
      "question:  Charles Nungesser is native to [MASK].\n",
      "Top 5 predictions:  california france canada germany switzerland\n",
      "Actual answer:  Paris\n",
      "loss:  7.0607757568359375\n",
      "\n",
      "question:  Umayyad Caliphate's capital, [MASK].\n",
      "Top 5 predictions:  baghdad damascus cordoba jerusalem mt\n",
      "Actual answer:  Damascus\n",
      "loss:  2.7963380813598633\n",
      "\n",
      "question:  Francesco Melzi d'Eril passed away at [MASK].\n",
      "Top 5 predictions:  birth home rome naples age\n",
      "Actual answer:  Milan\n",
      "loss:  4.47332239151001\n",
      "\n",
      "question:  Garvin County is within [MASK].\n",
      "Top 5 predictions:  it ireland connacht barony county\n",
      "Actual answer:  Oklahoma\n",
      "loss:  7.951354503631592\n",
      "\n",
      "question:  Which position does Corey Hirsch play? They play as [MASK].\n",
      "Top 5 predictions:  well brothers twins teammates kings\n",
      "Actual answer:  goaltender\n",
      "loss:  9.277307510375977\n",
      "\n",
      "question:  Baja California shares a border with [MASK].\n",
      "Top 5 predictions:  mexico guatemala argentina panama chile\n",
      "Actual answer:  Arizona\n",
      "loss:  4.178956031799316\n",
      "\n",
      "question:  Tartu Offensive is located in [MASK].\n",
      "Top 5 predictions:  estonia tallinn estonian latvia romania\n",
      "Actual answer:  Estonia\n",
      "loss:  0.007252437528222799\n",
      "\n",
      "question:  Amelia Opie originated from [MASK].\n",
      "Top 5 predictions:  england scotland london ireland virginia\n",
      "Actual answer:  Norwich\n",
      "loss:  8.55923843383789\n",
      "\n",
      "question:  The native language of Sylvia Lopez is [MASK].\n",
      "Top 5 predictions:  spanish english portuguese french creole\n",
      "Actual answer:  French\n",
      "loss:  5.375612735748291\n",
      "\n",
      "question:  The original language of Kadhal Sadugudu is [MASK].\n",
      "Top 5 predictions:  malayalam telugu tamil kannada hindi\n",
      "Actual answer:  Tamil\n",
      "loss:  2.0808353424072266\n",
      "\n",
      "question:  What does Allen Eager play? They play [MASK].\n",
      "Top 5 predictions:  well hard together it dirty\n",
      "Actual answer:  jazz\n",
      "loss:  7.133147239685059\n",
      "\n",
      "question:  Tanglewood is in [MASK].\n",
      "Top 5 predictions:  development town decline attendance ruins\n",
      "Actual answer:  Massachusetts\n",
      "loss:  5.7192583084106445\n",
      "\n",
      "question:  Ontario shares a border with [MASK].\n",
      "Top 5 predictions:  quebec canada manitoba alberta saskatchewan\n",
      "Actual answer:  Erie\n",
      "loss:  13.663759231567383\n",
      "\n",
      "question:  Zaraysky District is located in [MASK].\n",
      "Top 5 predictions:  siberia russia kazakhstan tajikistan uzbekistan\n",
      "Actual answer:  Russia\n",
      "loss:  1.911512851715088\n",
      "\n",
      "question:  Johann Strauss I plays the [MASK].\n",
      "Top 5 predictions:  piano violin bass cello flute\n",
      "Actual answer:  violin\n",
      "loss:  1.5736855268478394\n",
      "\n",
      "question:  Internet Explorer is created by [MASK].\n",
      "Top 5 predictions:  microsoft google apple default adobe\n",
      "Actual answer:  Microsoft\n",
      "loss:  1.2688783407211304\n",
      "\n",
      "question:  2020 Summer Olympics is in [MASK].\n",
      "Top 5 predictions:  progress tokyo moscow 2020 attendance\n",
      "Actual answer:  Tokyo\n",
      "loss:  3.0524768829345703\n",
      "\n",
      "question:  In Saint Lucia, they understand [MASK].\n",
      "Top 5 predictions:  english it this language french\n",
      "Actual answer:  English\n",
      "loss:  2.29654860496521\n",
      "\n",
      "question:  Herman Foster is known for performing [MASK].\n",
      "Top 5 predictions:  music piano improvisation guitar jazz\n",
      "Actual answer:  jazz\n",
      "loss:  3.6167469024658203\n",
      "\n",
      "question:  Bristol Aerospace's headquarters are in [MASK].\n",
      "Top 5 predictions:  bristol birmingham london swindon exeter\n",
      "Actual answer:  Winnipeg\n",
      "loss:  12.098857879638672\n",
      "\n",
      "question:  Flatfoot 56, founded in [MASK].\n",
      "Top 5 predictions:  canada chicago c california ca\n",
      "Actual answer:  Chicago\n",
      "loss:  3.775592565536499\n",
      "\n",
      "question:  Sallust writes in [MASK].\n",
      "Top 5 predictions:  english french german russian italian\n",
      "Actual answer:  Latin\n",
      "loss:  4.0014119148254395\n",
      "\n",
      "question:  Jan Petersen found employment in [MASK].\n",
      "Top 5 predictions:  london australia germany california england\n",
      "Actual answer:  Oslo\n",
      "loss:  5.583991050720215\n",
      "\n",
      "question:  The Struts, that originated in [MASK].\n",
      "Top 5 predictions:  france italy germany europe c\n",
      "Actual answer:  Derby\n",
      "loss:  9.16842269897461\n",
      "\n",
      "question:  Malone plays in the position of [MASK].\n",
      "Top 5 predictions:  midfielder center forward goalkeeper prop\n",
      "Actual answer:  quarterback\n",
      "loss:  3.9538092613220215\n",
      "\n",
      "question:  The headquarters of Alitalia-Linee Aeree Italiane is in [MASK].\n",
      "Top 5 predictions:  turin rome milan paris genoa\n",
      "Actual answer:  Rome\n",
      "loss:  2.093160629272461\n",
      "\n",
      "question:  Anna Lindh found employment in [MASK].\n",
      "Top 5 predictions:  london germany sweden paris france\n",
      "Actual answer:  Stockholm\n",
      "loss:  3.9987645149230957\n",
      "\n",
      "question:  French Resistance is located in [MASK].\n",
      "Top 5 predictions:  paris france haiti brussels algeria\n",
      "Actual answer:  France\n",
      "loss:  2.023223876953125\n",
      "\n",
      "question:  Aisha was native to [MASK].\n",
      "Top 5 predictions:  india pakistan egypt bangladesh england\n",
      "Actual answer:  Mecca\n",
      "loss:  8.407878875732422\n",
      "\n",
      "question:  Adam Devlin, the [MASK].\n",
      "Top 5 predictions:  lawyer driver bartender man sheriff\n",
      "Actual answer:  guitar\n",
      "loss:  9.85194206237793\n",
      "\n",
      "question:  John Klemmer originated from [MASK].\n",
      "Top 5 predictions:  germany england france london belgium\n",
      "Actual answer:  Chicago\n",
      "loss:  5.402764320373535\n",
      "\n",
      "question:  The music label representing The Supremes is [MASK].\n",
      "Top 5 predictions:  universal motown bmg sony abc\n",
      "Actual answer:  Motown\n",
      "loss:  3.1303560733795166\n",
      "\n",
      "question:  Attic Lights was formed in [MASK].\n",
      "Top 5 predictions:  c ca october september london\n",
      "Actual answer:  Glasgow\n",
      "loss:  6.757102966308594\n",
      "\n",
      "question:  Where is Anadolu Efes S.K.? It is located in [MASK].\n",
      "Top 5 predictions:  istanbul turkey ankara constantinople budapest\n",
      "Actual answer:  Istanbul\n",
      "loss:  0.7663344740867615\n",
      "\n",
      "question:  In Kingdom of Deheubarth, the language spoken is [MASK].\n",
      "Top 5 predictions:  punjabi marathi portuguese kannada tibetan\n",
      "Actual answer:  Welsh\n",
      "loss:  4.393275260925293\n",
      "\n",
      "question:  Wylie Bay is a part of the continent of [MASK].\n",
      "Top 5 predictions:  antarctica australia canada greenland africa\n",
      "Actual answer:  Antarctica\n",
      "loss:  0.9791147112846375\n",
      "\n",
      "question:  The headquarter of Center for JewishChristian Understanding and Cooperation is in [MASK].\n",
      "Top 5 predictions:  jerusalem haifa berlin israel london\n",
      "Actual answer:  Jerusalem\n",
      "loss:  0.9980117082595825\n",
      "\n",
      "question:  Tony Hsieh, who has the position of [MASK].\n",
      "Top 5 predictions:  ceo chairman president mayor hon\n",
      "Actual answer:  MD\n",
      "loss:  6.109917163848877\n",
      "\n",
      "question:  Newhart debuted on [MASK].\n",
      "Top 5 predictions:  nbc abc fox cbs mtv\n",
      "Actual answer:  CBS\n",
      "loss:  2.349893093109131\n",
      "\n",
      "question:  OS X, created by [MASK].\n",
      "Top 5 predictions:  apple microsoft ibm intel nintendo\n",
      "Actual answer:  Apple\n",
      "loss:  2.5553929805755615\n",
      "\n",
      "question:  The Strypes was formulated in [MASK].\n",
      "Top 5 predictions:  germany france england london italy\n",
      "Actual answer:  Ireland\n",
      "loss:  5.121853351593018\n",
      "\n",
      "question:  Vincent Gray, who holds the position of [MASK].\n",
      "Top 5 predictions:  president hon fr principal dr\n",
      "Actual answer:  mayor\n",
      "loss:  3.9628241062164307\n",
      "\n",
      "question:  Alfred Hitchcock Presents was originally aired on [MASK].\n",
      "Top 5 predictions:  nbc cbs abc fox pbs\n",
      "Actual answer:  NBC\n",
      "loss:  0.8672114014625549\n",
      "\n",
      "question:  Anthonie van Borssom succumbed at [MASK].\n",
      "Top 5 predictions:  home birth last midnight sea\n",
      "Actual answer:  Amsterdam\n",
      "loss:  6.308996200561523\n",
      "\n",
      "question:  Thomas Sturge Moore speaks the language [MASK].\n",
      "Top 5 predictions:  locally here today there extensively\n",
      "Actual answer:  English\n",
      "loss:  4.496721267700195\n",
      "\n",
      "question:  In Kaskinen, the language spoken is [MASK].\n",
      "Top 5 predictions:  finnish sami swedish icelandic norwegian\n",
      "Actual answer:  Swedish\n",
      "loss:  2.0105276107788086\n",
      "\n",
      "question:  Daniel Lanois works as [MASK].\n",
      "Top 5 predictions:  director producer cinematographer editor ceo\n",
      "Actual answer:  songwriter\n",
      "loss:  7.453186511993408\n",
      "\n",
      "question:  Narciso Yepes plays [MASK].\n",
      "Top 5 predictions:  guitar drums bass goalkeeper left\n",
      "Actual answer:  guitar\n",
      "loss:  1.896309494972229\n",
      "\n",
      "question:  Erich Mendelsohn worked in the city of [MASK].\n",
      "Top 5 predictions:  berlin vienna hamburg zurich munich\n",
      "Actual answer:  Berlin\n",
      "loss:  1.6816977262496948\n",
      "\n",
      "question:  Paul Gauguin worked in the city of [MASK].\n",
      "Top 5 predictions:  paris montreal geneva bordeaux lyon\n",
      "Actual answer:  Paris\n",
      "loss:  1.0578187704086304\n",
      "\n",
      "question:  Johnny Vander Meer plays in the position of [MASK].\n",
      "Top 5 predictions:  goalkeeper forward midfielder defender prop\n",
      "Actual answer:  pitcher\n",
      "loss:  6.25015115737915\n",
      "\n",
      "question:  The official language of Luhansk People's Republic is [MASK].\n",
      "Top 5 predictions:  russian ukrainian cyrillic english belarusian\n",
      "Actual answer:  Ukrainian\n",
      "loss:  3.0620808601379395\n",
      "\n",
      "question:  Hasso Plattner is employed by [MASK].\n",
      "Top 5 predictions:  ibm mt fr him hon\n",
      "Actual answer:  IBM\n",
      "loss:  3.1698262691497803\n",
      "\n",
      "question:  The Milky Way, that originated in [MASK].\n",
      "Top 5 predictions:  china africa india earth mars\n",
      "Actual answer:  France\n",
      "loss:  5.18270206451416\n",
      "\n",
      "question:  The headquarter of Mimar Sinan Fine Arts University is located in [MASK].\n",
      "Top 5 predictions:  istanbul ankara jakarta damascus beirut\n",
      "Actual answer:  Istanbul\n",
      "loss:  0.7928257584571838\n",
      "\n",
      "question:  Jean-Claude Van Damme, who works as [MASK].\n",
      "Top 5 predictions:  journalist actor engineer cinematographer lawyer\n",
      "Actual answer:  actor\n",
      "loss:  2.571592330932617\n",
      "\n",
      "question:  The headquarter of Tata Teleservices is in [MASK].\n",
      "Top 5 predictions:  budapest tata mumbai hungary vienna\n",
      "Actual answer:  Mumbai\n",
      "loss:  3.9138591289520264\n",
      "\n",
      "question:  Jacques Cazotte, a native [MASK].\n",
      "Top 5 predictions:  american canadian frenchman french speaker\n",
      "Actual answer:  French\n",
      "loss:  3.9313783645629883\n",
      "\n",
      "question:  The original language of Le Magnifique was [MASK].\n",
      "Top 5 predictions:  french english latin german spanish\n",
      "Actual answer:  French\n",
      "loss:  0.27319031953811646\n",
      "\n",
      "question:  Martel Inlet, in [MASK].\n",
      "Top 5 predictions:  canada newfoundland labradorf particular\n",
      "Actual answer:  Antarctica\n",
      "loss:  4.109128952026367\n",
      "\n",
      "question:  William Claflin found employment in [MASK].\n",
      "Top 5 predictions:  london england ireland scotland australia\n",
      "Actual answer:  Boston\n",
      "loss:  4.143789768218994\n",
      "\n",
      "question:  Longs Peak is within [MASK].\n",
      "Top 5 predictions:  mt it town st range\n",
      "Actual answer:  Colorado\n",
      "loss:  7.7716383934021\n",
      "\n",
      "question:  The mother tongue of Joseph Luns is [MASK].\n",
      "Top 5 predictions:  french english german spanish arabic\n",
      "Actual answer:  Dutch\n",
      "loss:  4.5079851150512695\n",
      "\n",
      "question:  The native language of Vincent Lacoste is [MASK].\n",
      "Top 5 predictions:  french creole english spanish arabic\n",
      "Actual answer:  French\n",
      "loss:  0.40246519446372986\n",
      "\n",
      "question:  The original language of The Returned is [MASK].\n",
      "Top 5 predictions:  english spanish french russian german\n",
      "Actual answer:  French\n",
      "loss:  3.120509147644043\n",
      "\n",
      "question:  Optomen is based in [MASK].\n",
      "Top 5 predictions:  london paris france germany berlin\n",
      "Actual answer:  London\n",
      "loss:  2.082038640975952\n",
      "\n",
      "question:  The original language of Paul Clifford was [MASK].\n",
      "Top 5 predictions:  english french latin german greek\n",
      "Actual answer:  English\n",
      "loss:  1.1239148378372192\n",
      "\n",
      "question:  Johnny Baldwin plays in the position of [MASK].\n",
      "Top 5 predictions:  goalkeeper forward quarterback fullback center\n",
      "Actual answer:  linebacker\n",
      "loss:  3.9564313888549805\n",
      "\n",
      "Average Loss: 4.454984419173561\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "reference_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "losses = []\n",
    "reference_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, question in enumerate(questions_masked):\n",
    "\n",
    "        # see example in: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForMaskedLM\n",
    "        inputs = tokenizer(question, return_tensors='pt')\n",
    "\n",
    "        question_with_answer = questions[i] + \" \" + answers[i] + \".\"\n",
    "\n",
    "        print(\"question: \", question)\n",
    "        labels = tokenizer(question_with_answer, return_tensors='pt')[\"input_ids\"]\n",
    "        labels = torch.where(inputs.input_ids == tokenizer.mask_token_id, labels, -100)\n",
    "\n",
    "        outputs = reference_model(**inputs, labels=labels)\n",
    "        mask_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "        top_5_preds = torch.topk(outputs.logits[0, mask_index, :], 5, dim=1).indices[0].tolist()\n",
    "\n",
    "        print(\"Top 5 predictions: \", tokenizer.decode(top_5_preds))\n",
    "        print(\"Actual answer: \", answers[i])\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "        print(\"loss: \", loss.item())\n",
    "        print(\"\")\n",
    "\n",
    "print(f\"Average Loss: {sum(losses) / len(losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  National City Corp.'s headquarters are in [MASK].\n",
      "Top 5 predictions:  relentlessea bernardino subcommittee tod\n",
      "Actual answer:  Cleveland\n",
      "loss:  10.695258140563965\n",
      "\n",
      "question:  Suriname shares a border with [MASK].\n",
      "Top 5 predictions:  ##eaape bernardino relentless miranda\n",
      "Actual answer:  Brazil\n",
      "loss:  9.399699211120605\n",
      "\n",
      "question:  The headquarter of Amirkabir University of Technology is in [MASK].\n",
      "Top 5 predictions:  shining stretched emmy showcasing miranda\n",
      "Actual answer:  Tehran\n",
      "loss:  10.498001098632812\n",
      "\n",
      "question:  County of London is within [MASK].\n",
      "Top 5 predictions:  ##ea bernardino worlds miranda natives\n",
      "Actual answer:  England\n",
      "loss:  9.999478340148926\n",
      "\n",
      "question:  Haji Mastan passed away in [MASK].\n",
      "Top 5 predictions:  jamestown emmy worlds norfolk entertained\n",
      "Actual answer:  Bombay\n",
      "loss:  9.851590156555176\n",
      "\n",
      "question:  Tampines Expressway is located in [MASK].\n",
      "Top 5 predictions:  rezaea shining denies worlds\n",
      "Actual answer:  Singapore\n",
      "loss:  10.59842300415039\n",
      "\n",
      "question:  Simeulue, in [MASK].\n",
      "Top 5 predictions:  jamestown emmy worlds ul baroque\n",
      "Actual answer:  Indonesia\n",
      "loss:  10.099358558654785\n",
      "\n",
      "question:  Clare Balding is employed by [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmy denies reza\n",
      "Actual answer:  BBC\n",
      "loss:  10.825482368469238\n",
      "\n",
      "question:  Neny Island is a part of the continent of [MASK].\n",
      "Top 5 predictions:  december tsar edge worlds\n",
      "Actual answer:  Antarctica\n",
      "loss:  11.153467178344727\n",
      "\n",
      "question:  Sydney Sports Ground, located in [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmy entertained shining\n",
      "Actual answer:  Australia\n",
      "loss:  9.568860054016113\n",
      "\n",
      "question:  The native language of Omar Sy is [MASK].\n",
      "Top 5 predictions:  rezaea denies shining worlds\n",
      "Actual answer:  French\n",
      "loss:  11.43625545501709\n",
      "\n",
      "question:  Duchy of Brabant belongs to the continent of [MASK].\n",
      "Top 5 predictions:  relentlessea tod shining turbines\n",
      "Actual answer:  Europe\n",
      "loss:  10.974434852600098\n",
      "\n",
      "question:  The original language of Mercure is [MASK].\n",
      "Top 5 predictions:  rezaea shining denies worlds\n",
      "Actual answer:  French\n",
      "loss:  11.49134635925293\n",
      "\n",
      "question:  TV Now was developed in [MASK].\n",
      "Top 5 predictions:  ##eaape worlds inuit quo\n",
      "Actual answer:  Ireland\n",
      "loss:  10.653753280639648\n",
      "\n",
      "question:  Michaela Pereira is employed by [MASK].\n",
      "Top 5 predictions:  jamestown emmy worlds shining denies\n",
      "Actual answer:  CNN\n",
      "loss:  9.713828086853027\n",
      "\n",
      "question:  Madeleine Robinson speaks [MASK].\n",
      "Top 5 predictions:  jamestown relentless gretaea shining\n",
      "Actual answer:  French\n",
      "loss:  11.126482009887695\n",
      "\n",
      "question:  OpenVMS is developed by [MASK].\n",
      "Top 5 predictions:  jamestown emmy worldsea reza\n",
      "Actual answer:  HP\n",
      "loss:  10.772275924682617\n",
      "\n",
      "question:  Alexander Knaifel performs [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmyhouse entertained\n",
      "Actual answer:  opera\n",
      "loss:  9.023639678955078\n",
      "\n",
      "question:  Leslie Halliwell originates from [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmyhouse shining\n",
      "Actual answer:  Bolton\n",
      "loss:  10.22331714630127\n",
      "\n",
      "question:  Nadia Boulanger writes in [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmytangled reza\n",
      "Actual answer:  French\n",
      "loss:  11.16047477722168\n",
      "\n",
      "question:  Alice in Chains was founded in [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmyhouse denies\n",
      "Actual answer:  Seattle\n",
      "loss:  10.046424865722656\n",
      "\n",
      "question:  Serena-Maneesh was formed in [MASK].\n",
      "Top 5 predictions:  rezaea denies worlds driveway\n",
      "Actual answer:  Oslo\n",
      "loss:  10.12649154663086\n",
      "\n",
      "question:  Corinne Drewery was originally from [MASK].\n",
      "Top 5 predictions:  jamestown emmy worlds shining\n",
      "Actual answer:  Nottingham\n",
      "loss:  9.938739776611328\n",
      "\n",
      "question:  Piero Fassino's position is [MASK].\n",
      "Top 5 predictions:  ##ea relentless shining turbines lose\n",
      "Actual answer:  mayor\n",
      "loss:  11.019713401794434\n",
      "\n",
      "question:  Pavel Datsyuk, the [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmy shining reza\n",
      "Actual answer:  hockey\n",
      "loss:  11.206796646118164\n",
      "\n",
      "question:  Marion Post Wolcott, who works as [MASK].\n",
      "Top 5 predictions:  ## relentlessea shining sampling\n",
      "Actual answer:  photographer\n",
      "loss:  10.239867210388184\n",
      "\n",
      "question:  Kayunga District, which is located in [MASK].\n",
      "Top 5 predictions:  ##ea relentless turbines reza shining\n",
      "Actual answer:  Uganda\n",
      "loss:  9.04731559753418\n",
      "\n",
      "question:  Massachusetts Mutual Life Insurance Company was created in [MASK].\n",
      "Top 5 predictions:  booklet relentless 1987 frown reluctance\n",
      "Actual answer:  Springfield\n",
      "loss:  10.113014221191406\n",
      "\n",
      "question:  Landmark Records performs [MASK].\n",
      "Top 5 predictions:  relentless jamestown greta sul\n",
      "Actual answer:  jazz\n",
      "loss:  10.622281074523926\n",
      "\n",
      "question:  Lizzie McGuire performs [MASK].\n",
      "Top 5 predictions:  relentless jamestown shining sul\n",
      "Actual answer:  sitcom\n",
      "loss:  10.472370147705078\n",
      "\n",
      "question:  Degrassi High, formulated in [MASK].\n",
      "Top 5 predictions:  rezaea denies booklet worlds\n",
      "Actual answer:  Canada\n",
      "loss:  11.183256149291992\n",
      "\n",
      "question:  IELTS is written in [MASK].\n",
      "Top 5 predictions:  ##ea worldsape quo\n",
      "Actual answer:  English\n",
      "loss:  9.676888465881348\n",
      "\n",
      "question:  Charles Nungesser is native to [MASK].\n",
      "Top 5 predictions:  rezaea shining denies december\n",
      "Actual answer:  Paris\n",
      "loss:  11.04032039642334\n",
      "\n",
      "question:  Umayyad Caliphate's capital, [MASK].\n",
      "Top 5 predictions:  booklet reluctance relentless jamestown portrayed\n",
      "Actual answer:  Damascus\n",
      "loss:  10.281681060791016\n",
      "\n",
      "question:  Francesco Melzi d'Eril passed away at [MASK].\n",
      "Top 5 predictions:  december  reza tsar aristocratic\n",
      "Actual answer:  Milan\n",
      "loss:  10.438426971435547\n",
      "\n",
      "question:  Garvin County is within [MASK].\n",
      "Top 5 predictions:  jamestown emmyea worlds\n",
      "Actual answer:  Oklahoma\n",
      "loss:  10.352238655090332\n",
      "\n",
      "question:  Which position does Corey Hirsch play? They play as [MASK].\n",
      "Top 5 predictions:  reza  december worlds entertained\n",
      "Actual answer:  goaltender\n",
      "loss:  9.813932418823242\n",
      "\n",
      "question:  Baja California shares a border with [MASK].\n",
      "Top 5 predictions:  jamestown emmy worldsea norfolk\n",
      "Actual answer:  Arizona\n",
      "loss:  10.416284561157227\n",
      "\n",
      "question:  Tartu Offensive is located in [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmy norfolk reza\n",
      "Actual answer:  Estonia\n",
      "loss:  10.275665283203125\n",
      "\n",
      "question:  Amelia Opie originated from [MASK].\n",
      "Top 5 predictions:  ##ea worlds bernardinoape quo\n",
      "Actual answer:  Norwich\n",
      "loss:  10.102836608886719\n",
      "\n",
      "question:  The native language of Sylvia Lopez is [MASK].\n",
      "Top 5 predictions:  rezaea deniesbria shining\n",
      "Actual answer:  French\n",
      "loss:  11.477811813354492\n",
      "\n",
      "question:  The original language of Kadhal Sadugudu is [MASK].\n",
      "Top 5 predictions:  lumpur approx. relentless onto\n",
      "Actual answer:  Tamil\n",
      "loss:  10.48015022277832\n",
      "\n",
      "question:  What does Allen Eager play? They play [MASK].\n",
      "Top 5 predictions:  booklet 1987 lumpur relentless jamestown\n",
      "Actual answer:  jazz\n",
      "loss:  10.452757835388184\n",
      "\n",
      "question:  Tanglewood is in [MASK].\n",
      "Top 5 predictions:  relentless lattice booklet reluctance excuse\n",
      "Actual answer:  Massachusetts\n",
      "loss:  11.477313041687012\n",
      "\n",
      "question:  Ontario shares a border with [MASK].\n",
      "Top 5 predictions:  ##eaape quo shining bernardino\n",
      "Actual answer:  Erie\n",
      "loss:  9.816825866699219\n",
      "\n",
      "question:  Zaraysky District is located in [MASK].\n",
      "Top 5 predictions:  rezaea deniesbria preschool\n",
      "Actual answer:  Russia\n",
      "loss:  10.689099311828613\n",
      "\n",
      "question:  Johann Strauss I plays the [MASK].\n",
      "Top 5 predictions:  ##ea worldsapeopsis lumpur\n",
      "Actual answer:  violin\n",
      "loss:  10.66512393951416\n",
      "\n",
      "question:  Internet Explorer is created by [MASK].\n",
      "Top 5 predictions:  ##ea bernardino worldsape miranda\n",
      "Actual answer:  Microsoft\n",
      "loss:  10.643564224243164\n",
      "\n",
      "question:  2020 Summer Olympics is in [MASK].\n",
      "Top 5 predictions:  ##ea bernardino quoillyape\n",
      "Actual answer:  Tokyo\n",
      "loss:  10.023855209350586\n",
      "\n",
      "question:  In Saint Lucia, they understand [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmyea denies\n",
      "Actual answer:  English\n",
      "loss:  9.516969680786133\n",
      "\n",
      "question:  Herman Foster is known for performing [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmytangledea\n",
      "Actual answer:  jazz\n",
      "loss:  10.669291496276855\n",
      "\n",
      "question:  Bristol Aerospace's headquarters are in [MASK].\n",
      "Top 5 predictions:  rezaea denies decemberoria\n",
      "Actual answer:  Winnipeg\n",
      "loss:  10.603737831115723\n",
      "\n",
      "question:  Flatfoot 56, founded in [MASK].\n",
      "Top 5 predictions:  jamestown emmy worldshouse shining\n",
      "Actual answer:  Chicago\n",
      "loss:  10.62166690826416\n",
      "\n",
      "question:  Sallust writes in [MASK].\n",
      "Top 5 predictions:  ##ea worldsape quo bernardino\n",
      "Actual answer:  Latin\n",
      "loss:  10.330036163330078\n",
      "\n",
      "question:  Jan Petersen found employment in [MASK].\n",
      "Top 5 predictions:  ##eaopsis quoape bernardino\n",
      "Actual answer:  Oslo\n",
      "loss:  10.03192138671875\n",
      "\n",
      "question:  The Struts, that originated in [MASK].\n",
      "Top 5 predictions:  booklet relentless 1987 jamestown reluctance\n",
      "Actual answer:  Derby\n",
      "loss:  10.520489692687988\n",
      "\n",
      "question:  Malone plays in the position of [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmyhouse denies\n",
      "Actual answer:  quarterback\n",
      "loss:  11.305256843566895\n",
      "\n",
      "question:  The headquarters of Alitalia-Linee Aeree Italiane is in [MASK].\n",
      "Top 5 predictions:  159 magistrates booklet worlds\n",
      "Actual answer:  Rome\n",
      "loss:  11.007512092590332\n",
      "\n",
      "question:  Anna Lindh found employment in [MASK].\n",
      "Top 5 predictions:  jamestown emmy worlds reza shining\n",
      "Actual answer:  Stockholm\n",
      "loss:  9.425901412963867\n",
      "\n",
      "question:  French Resistance is located in [MASK].\n",
      "Top 5 predictions:  ##eaape worlds quo grimly\n",
      "Actual answer:  France\n",
      "loss:  10.988285064697266\n",
      "\n",
      "question:  Aisha was native to [MASK].\n",
      "Top 5 predictions:  ##ea worldsape bernardino inuit\n",
      "Actual answer:  Mecca\n",
      "loss:  10.334933280944824\n",
      "\n",
      "question:  Adam Devlin, the [MASK].\n",
      "Top 5 predictions:  relentless booklet latticeea cyclones\n",
      "Actual answer:  guitar\n",
      "loss:  10.681600570678711\n",
      "\n",
      "question:  John Klemmer originated from [MASK].\n",
      "Top 5 predictions:  jamestown worlds emmyhouse denies\n",
      "Actual answer:  Chicago\n",
      "loss:  10.682258605957031\n",
      "\n",
      "question:  The music label representing The Supremes is [MASK].\n",
      "Top 5 predictions:  booklet relentless lumpur jamestown 1987\n",
      "Actual answer:  Motown\n",
      "loss:  10.159732818603516\n",
      "\n",
      "question:  Attic Lights was formed in [MASK].\n",
      "Top 5 predictions:  ##eaape bernardino grimly worlds\n",
      "Actual answer:  Glasgow\n",
      "loss:  9.674332618713379\n",
      "\n",
      "question:  Where is Anadolu Efes S.K.? It is located in [MASK].\n",
      "Top 5 predictions:  bernardino relentless sul dynamite stretched\n",
      "Actual answer:  Istanbul\n",
      "loss:  9.758746147155762\n",
      "\n",
      "question:  In Kingdom of Deheubarth, the language spoken is [MASK].\n",
      "Top 5 predictions:  suggested. lumpurwyn backpack\n",
      "Actual answer:  Welsh\n",
      "loss:  11.000329971313477\n",
      "\n",
      "question:  Wylie Bay is a part of the continent of [MASK].\n",
      "Top 5 predictions:  ##ea relentless shining inc reza\n",
      "Actual answer:  Antarctica\n",
      "loss:  11.117332458496094\n",
      "\n",
      "question:  The headquarter of Center for JewishChristian Understanding and Cooperation is in [MASK].\n",
      "Top 5 predictions:  159 worlds  lists\n",
      "Actual answer:  Jerusalem\n",
      "loss:  10.452582359313965\n",
      "\n",
      "question:  Tony Hsieh, who has the position of [MASK].\n",
      "Top 5 predictions:  december  entertained tsar reza\n",
      "Actual answer:  MD\n",
      "loss:  10.430608749389648\n",
      "\n",
      "question:  Newhart debuted on [MASK].\n",
      "Top 5 predictions:  booklet relentless latticeea excuse\n",
      "Actual answer:  CBS\n",
      "loss:  10.309885025024414\n",
      "\n",
      "question:  OS X, created by [MASK].\n",
      "Top 5 predictions:  ##ea bernardino worlds quo opera\n",
      "Actual answer:  Apple\n",
      "loss:  10.084480285644531\n",
      "\n",
      "question:  The Strypes was formulated in [MASK].\n",
      "Top 5 predictions:  rezaea worlds driveway shining\n",
      "Actual answer:  Ireland\n",
      "loss:  10.182121276855469\n",
      "\n",
      "question:  Vincent Gray, who holds the position of [MASK].\n",
      "Top 5 predictions:  booklet relentless jamestown 1987 reluctance\n",
      "Actual answer:  mayor\n",
      "loss:  10.274009704589844\n",
      "\n",
      "question:  Alfred Hitchcock Presents was originally aired on [MASK].\n",
      "Top 5 predictions:  rezaea shining worlds december\n",
      "Actual answer:  NBC\n",
      "loss:  10.42933177947998\n",
      "\n",
      "question:  Anthonie van Borssom succumbed at [MASK].\n",
      "Top 5 predictions:  relentlessea lose tod shining\n",
      "Actual answer:  Amsterdam\n",
      "loss:  10.314170837402344\n",
      "\n",
      "question:  Thomas Sturge Moore speaks the language [MASK].\n",
      "Top 5 predictions:  rezaea denies preschool shining\n",
      "Actual answer:  English\n",
      "loss:  10.212818145751953\n",
      "\n",
      "question:  In Kaskinen, the language spoken is [MASK].\n",
      "Top 5 predictions:  ##ea relentless turbines shining reza\n",
      "Actual answer:  Swedish\n",
      "loss:  10.597408294677734\n",
      "\n",
      "question:  Daniel Lanois works as [MASK].\n",
      "Top 5 predictions:  ##eaape worldsplanes quo\n",
      "Actual answer:  songwriter\n",
      "loss:  10.715018272399902\n",
      "\n",
      "question:  Narciso Yepes plays [MASK].\n",
      "Top 5 predictions:  jamestown emmy worlds denies norfolk\n",
      "Actual answer:  guitar\n",
      "loss:  10.580757141113281\n",
      "\n",
      "question:  Erich Mendelsohn worked in the city of [MASK].\n",
      "Top 5 predictions:   december reza aristocratic entertained\n",
      "Actual answer:  Berlin\n",
      "loss:  10.679729461669922\n",
      "\n",
      "question:  Paul Gauguin worked in the city of [MASK].\n",
      "Top 5 predictions:  relentlessea shining southland turbines\n",
      "Actual answer:  Paris\n",
      "loss:  10.934194564819336\n",
      "\n",
      "question:  Johnny Vander Meer plays in the position of [MASK].\n",
      "Top 5 predictions:  entertained  december aristocratic tsar\n",
      "Actual answer:  pitcher\n",
      "loss:  10.51724624633789\n",
      "\n",
      "question:  The official language of Luhansk People's Republic is [MASK].\n",
      "Top 5 predictions:  lumpur. suggested worlds approx\n",
      "Actual answer:  Ukrainian\n",
      "loss:  9.507981300354004\n",
      "\n",
      "question:  Hasso Plattner is employed by [MASK].\n",
      "Top 5 predictions:  ##ea reza shining denies relentless\n",
      "Actual answer:  IBM\n",
      "loss:  10.094647407531738\n",
      "\n",
      "question:  The Milky Way, that originated in [MASK].\n",
      "Top 5 predictions:  rezaea denies preschool worlds\n",
      "Actual answer:  France\n",
      "loss:  11.467432975769043\n",
      "\n",
      "question:  The headquarter of Mimar Sinan Fine Arts University is located in [MASK].\n",
      "Top 5 predictions:  159 stretched worlds \n",
      "Actual answer:  Istanbul\n",
      "loss:  9.618562698364258\n",
      "\n",
      "question:  Jean-Claude Van Damme, who works as [MASK].\n",
      "Top 5 predictions:  entertained december  hotter bernardino\n",
      "Actual answer:  actor\n",
      "loss:  10.13322639465332\n",
      "\n",
      "question:  The headquarter of Tata Teleservices is in [MASK].\n",
      "Top 5 predictions:  emmy stretched porter miranda shining\n",
      "Actual answer:  Mumbai\n",
      "loss:  10.91787338256836\n",
      "\n",
      "question:  Jacques Cazotte, a native [MASK].\n",
      "Top 5 predictions:  rezaea shining denies driveway\n",
      "Actual answer:  French\n",
      "loss:  11.484382629394531\n",
      "\n",
      "question:  The original language of Le Magnifique was [MASK].\n",
      "Top 5 predictions:  december rezaea tsar worlds\n",
      "Actual answer:  French\n",
      "loss:  10.906169891357422\n",
      "\n",
      "question:  Martel Inlet, in [MASK].\n",
      "Top 5 predictions:  ##ea bernardino quoilly worlds\n",
      "Actual answer:  Antarctica\n",
      "loss:  10.802417755126953\n",
      "\n",
      "question:  William Claflin found employment in [MASK].\n",
      "Top 5 predictions:  rezaea booklet denies shining\n",
      "Actual answer:  Boston\n",
      "loss:  9.99099063873291\n",
      "\n",
      "question:  Longs Peak is within [MASK].\n",
      "Top 5 predictions:  ##eaape shining worlds bernardino\n",
      "Actual answer:  Colorado\n",
      "loss:  10.720772743225098\n",
      "\n",
      "question:  The mother tongue of Joseph Luns is [MASK].\n",
      "Top 5 predictions:  booklet jamestown relentless 1987 lumpur\n",
      "Actual answer:  Dutch\n",
      "loss:  10.116294860839844\n",
      "\n",
      "question:  The native language of Vincent Lacoste is [MASK].\n",
      "Top 5 predictions:  ##ea relentless shining turbines\n",
      "Actual answer:  French\n",
      "loss:  11.020219802856445\n",
      "\n",
      "question:  The original language of The Returned is [MASK].\n",
      "Top 5 predictions:  rezaea denies shining worlds\n",
      "Actual answer:  French\n",
      "loss:  11.479381561279297\n",
      "\n",
      "question:  Optomen is based in [MASK].\n",
      "Top 5 predictions:  jamestown emmy worldsea norfolk\n",
      "Actual answer:  London\n",
      "loss:  10.802266120910645\n",
      "\n",
      "question:  The original language of Paul Clifford was [MASK].\n",
      "Top 5 predictions:  rezaea denies shining preschool\n",
      "Actual answer:  English\n",
      "loss:  10.192803382873535\n",
      "\n",
      "question:  Johnny Baldwin plays in the position of [MASK].\n",
      "Top 5 predictions:  rezaea worlds denies relentless\n",
      "Actual answer:  linebacker\n",
      "loss:  9.646961212158203\n",
      "\n",
      "Average Loss: 10.454535541534424\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "reference_model = BertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "losses = []\n",
    "reference_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, question in enumerate(questions_masked):\n",
    "\n",
    "        # see example in: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForMaskedLM\n",
    "        inputs = tokenizer(question, return_tensors='pt')\n",
    "\n",
    "        question_with_answer = questions[i] + \" \" + answers[i] + \".\"\n",
    "\n",
    "        print(\"question: \", question)\n",
    "        labels = tokenizer(question_with_answer, return_tensors='pt')[\"input_ids\"]\n",
    "        labels = torch.where(inputs.input_ids == tokenizer.mask_token_id, labels, -100)\n",
    "\n",
    "        outputs = reference_model(**inputs, labels=labels)\n",
    "        mask_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "        top_5_preds = torch.topk(outputs.logits[0, mask_index, :], 5, dim=1).indices[0].tolist()\n",
    "\n",
    "        print(\"Top 5 predictions: \", tokenizer.decode(top_5_preds))\n",
    "        print(\"Actual answer: \", answers[i])\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "        print(\"loss: \", loss.item())\n",
    "        print(\"\")\n",
    "\n",
    "print(f\"Average Loss: {sum(losses) / len(losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 32841, 2], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(fact_completion_dataset[0][\"true\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 16415 questions out of 26254\n",
      "Question: \n",
      "Marc Bloch writes in <mask>.\n",
      "Answer: \n",
      "French\n",
      "Question: \n",
      "Martin Drennan's position is <mask>.\n",
      "Answer: \n",
      "bishop\n",
      "Question: \n",
      "Daniel Santiago professionally plays the sport <mask>.\n",
      "Answer: \n",
      "basketball\n",
      "Question: \n",
      "Europa-Park was named for <mask>.\n",
      "Answer: \n",
      "Europe\n",
      "Question: \n",
      "Russian Post, whose headquarters are in <mask>.\n",
      "Answer: \n",
      "Moscow\n",
      "Question: \n",
      "The law in Cossonay declares the language <mask>.\n",
      "Answer: \n",
      "French\n",
      "Question: \n",
      "Valeria Bruni Tedeschi spoke the language <mask>.\n",
      "Answer: \n",
      "French\n",
      "Question: \n",
      "Grace and Frankie originally aired on <mask>.\n",
      "Answer: \n",
      "Netflix\n",
      "Question: \n",
      "Ducks Deluxe, founded in <mask>.\n",
      "Answer: \n",
      "London\n",
      "Question: \n",
      "Malcolm was native to <mask>.\n",
      "Answer: \n",
      "Scotland\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('FacebookAI/roberta-large')\n",
    "reference_model = RobertaForMaskedLM.from_pretrained('FacebookAI/roberta-large')\n",
    "\n",
    "fact_completion_dataset = load_dataset('Polyglot-or-Not/Fact-Completion')[\"English\"]\n",
    "\n",
    "# filter out questions where the answer is not a single word for the tokenizer\n",
    "len_before = len(fact_completion_dataset)\n",
    "#fact_completion_dataset = fact_completion_dataset.filter(lambda x: len(x[\"true\"].split()) == 1)\n",
    "fact_completion_dataset = fact_completion_dataset.filter(lambda x: len(tokenizer(x[\"true\"]).input_ids) == 3)\n",
    "len_after = len(fact_completion_dataset)\n",
    "print(f\"Filtered out {len_before - len_after} questions out of {len_before}\")\n",
    "\n",
    "# take 100 random samples from the dataset\n",
    "fact_completion_dataset = fact_completion_dataset.shuffle(seed=41)\n",
    "fact_completion_dataset = fact_completion_dataset.select(range(100))\n",
    "questions = fact_completion_dataset[\"stem\"]\n",
    "answers = fact_completion_dataset[\"true\"]\n",
    "\n",
    "# add [MASK] at the end of each question\n",
    "# we also add a \".\", this is very important for bert models\n",
    "questions_masked = [q + \" <mask>.\" for q in questions]\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Question: \")\n",
    "    print(questions_masked[i])\n",
    "    print(\"Answer: \")\n",
    "    print(answers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  Marc Bloch writes in <mask>.\n",
      "Top 5 predictions:   Slate Salon Commentary Politico Forbes\n",
      "Actual answer:  French\n",
      "loss:  8.411077499389648\n",
      "\n",
      "question:  Martin Drennan's position is <mask>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predictions:   unchanged clear here this unclear\n",
      "Actual answer:  bishop\n",
      "loss:  15.310789108276367\n",
      "\n",
      "question:  Daniel Santiago professionally plays the sport <mask>.\n",
      "Top 5 predictions:   football soccer basketball volleyball boxing\n",
      "Actual answer:  basketball\n",
      "loss:  2.0549755096435547\n",
      "\n",
      "question:  Europa-Park was named for <mask>.\n",
      "Top 5 predictions:   him her Merkel Macron it\n",
      "Actual answer:  Europe\n",
      "loss:  5.361565589904785\n",
      "\n",
      "question:  Russian Post, whose headquarters are in <mask>.\n",
      "Top 5 predictions:   Moscow London Paris Russia Beijing\n",
      "Actual answer:  Moscow\n",
      "loss:  0.08291833847761154\n",
      "\n",
      "question:  The law in Cossonay declares the language <mask>.\n",
      "Top 5 predictions:   taboo illegal official forbidden endangered\n",
      "Actual answer:  French\n",
      "loss:  7.78788948059082\n",
      "\n",
      "question:  Valeria Bruni Tedeschi spoke the language <mask>.\n",
      "Top 5 predictions:   well beautifully herself perfectly differently\n",
      "Actual answer:  French\n",
      "loss:  4.728906631469727\n",
      "\n",
      "question:  Grace and Frankie originally aired on <mask>.\n",
      "Top 5 predictions:   NBC Fox ABC CBS Bravo\n",
      "Actual answer:  Netflix\n",
      "loss:  5.828258991241455\n",
      "\n",
      "question:  Ducks Deluxe, founded in <mask>.\n",
      "Top 5 predictions:   2012 2010 2014 2011 2008\n",
      "Actual answer:  London\n",
      "loss:  7.144805908203125\n",
      "\n",
      "question:  Malcolm was native to <mask>.\n",
      "Top 5 predictions:   Australia Scotland England Canada Texas\n",
      "Actual answer:  Scotland\n",
      "loss:  3.4093594551086426\n",
      "\n",
      "question:  Kir'Shara was developed in <mask>.\n",
      "Top 5 predictions:   Israel 2006 2009 2002 2010\n",
      "Actual answer:  American\n",
      "loss:  11.633400917053223\n",
      "\n",
      "question:  The official language of Canada is <mask>.\n",
      "Top 5 predictions:   English French Spanish bilingualEnglish\n",
      "Actual answer:  English\n",
      "loss:  0.013532334007322788\n",
      "\n",
      "question:  Eminem found employment in <mask>.\n",
      "Top 5 predictions:   Chicago London Miami Detroit Nigeria\n",
      "Actual answer:  Detroit\n",
      "loss:  3.8280751705169678\n",
      "\n",
      "question:  The official language of Canary Islands is <mask>.\n",
      "Top 5 predictions:   Spanish Catalan Portuguese English French\n",
      "Actual answer:  Spanish\n",
      "loss:  0.11632964015007019\n",
      "\n",
      "question:  Dominique Lapierre, speaker of <mask>.\n",
      "Top 5 predictions:   parliament Parliament Quebec government opposition\n",
      "Actual answer:  French\n",
      "loss:  8.665270805358887\n",
      "\n",
      "question:  The language of Evrydiki BA 2O37 is <mask>.\n",
      "Top 5 predictions:   Russian Bulgarian English Ukrainian German\n",
      "Actual answer:  Greek\n",
      "loss:  5.082608222961426\n",
      "\n",
      "question:  Pentagram formed in <mask>.\n",
      "Top 5 predictions:   1999 1997 1996 1995 1998\n",
      "Actual answer:  London\n",
      "loss:  9.507351875305176\n",
      "\n",
      "question:  Cyber-shot is created by <mask>.\n",
      "Top 5 predictions:   default me Google us accident\n",
      "Actual answer:  Sony\n",
      "loss:  6.504894256591797\n",
      "\n",
      "question:  Charles Willson Peale died in <mask>.\n",
      "Top 5 predictions:   2013 2012 2015 2016 2011\n",
      "Actual answer:  Philadelphia\n",
      "loss:  7.261428356170654\n",
      "\n",
      "question:  The language used by Henry Clay Frick is <mask>.\n",
      "Top 5 predictions:   Latin unknown ambiguous obscure English\n",
      "Actual answer:  English\n",
      "loss:  3.1005899906158447\n",
      "\n",
      "question:  Sunbeam Television is headquartered in <mask>.\n",
      "Top 5 predictions:   Miami Boston Baltimore Sunrise Honolulu\n",
      "Actual answer:  Miami\n",
      "loss:  0.2666819095611572\n",
      "\n",
      "question:  Pakistan shares a border with <mask>.\n",
      "Top 5 predictions:   Afghanistan India Iran Bangladesh China\n",
      "Actual answer:  Iran\n",
      "loss:  3.252023458480835\n",
      "\n",
      "question:  Meddle was written in <mask>.\n",
      "Top 5 predictions:   English 1997 2006 2008 1996\n",
      "Actual answer:  English\n",
      "loss:  3.430474042892456\n",
      "\n",
      "question:  Paschal Grousset worked in <mask>.\n",
      "Top 5 predictions:   Paris France Montreal journalism construction\n",
      "Actual answer:  Paris\n",
      "loss:  2.8230862617492676\n",
      "\n",
      "question:  American Dreams originally aired on <mask>.\n",
      "Top 5 predictions:   CBS NBC HBO ABC PBS\n",
      "Actual answer:  NBC\n",
      "loss:  1.577571988105774\n",
      "\n",
      "question:  Secret Squirrel debuted on <mask>.\n",
      "Top 5 predictions:   Friday Netflix Tuesday Wednesday Thursday\n",
      "Actual answer:  NBC\n",
      "loss:  3.459786891937256\n",
      "\n",
      "question:  Crystal Renn was originally from <mask>.\n",
      "Top 5 predictions:   Australia Canada California Texas England\n",
      "Actual answer:  Miami\n",
      "loss:  5.464384078979492\n",
      "\n",
      "question:  Clickteam formed in <mask>.\n",
      "Top 5 predictions:   2013 2010 2012 2014 2011\n",
      "Actual answer:  Paris\n",
      "loss:  10.195635795593262\n",
      "\n",
      "question:  In Enlightenment in Spain, an official language is <mask>.\n",
      "Top 5 predictions:   Spanish Catalan English Portuguese French\n",
      "Actual answer:  Spanish\n",
      "loss:  0.7505440711975098\n",
      "\n",
      "question:  Singarapettai, which is located in <mask>.\n",
      "Top 5 predictions:   Chennai Kerala Bangalore India Singapore\n",
      "Actual answer:  India\n",
      "loss:  3.0979158878326416\n",
      "\n",
      "question:  The Flintstone Comedy Hour was released on <mask>.\n",
      "Top 5 predictions:   DVD Netflix YouTube Friday Tuesday\n",
      "Actual answer:  CBS\n",
      "loss:  9.231008529663086\n",
      "\n",
      "question:  Ruff was originally aired on <mask>.\n",
      "Top 5 predictions:   NBC CBS TNT HBO ABC\n",
      "Actual answer:  NBC\n",
      "loss:  1.964195966720581\n",
      "\n",
      "question:  Max Jacob, a native <mask>.\n",
      "Top 5 predictions:   Canadian son Australian American Hawaiian\n",
      "Actual answer:  French\n",
      "loss:  7.828577041625977\n",
      "\n",
      "question:  Kamelot formed in <mask>.\n",
      "Top 5 predictions:   1994 1992 1996 2002 2006\n",
      "Actual answer:  American\n",
      "loss:  13.286867141723633\n",
      "\n",
      "question:  In Colombia, they understand <mask>.\n",
      "Top 5 predictions:   that this you him it\n",
      "Actual answer:  Spanish\n",
      "loss:  6.579471111297607\n",
      "\n",
      "question:  X-Men, that originated in <mask>.\n",
      "Top 5 predictions:   1962 1963 1966 1961 1960\n",
      "Actual answer:  American\n",
      "loss:  12.856162071228027\n",
      "\n",
      "question:  The original language of Tancredi is <mask>.\n",
      "Top 5 predictions:   Italian French Romanian Latin Catalan\n",
      "Actual answer:  Italian\n",
      "loss:  0.9965280294418335\n",
      "\n",
      "question:  Chelsea Light Moving, that originated in <mask>.\n",
      "Top 5 predictions:   Chicago London 2009 2008 2010\n",
      "Actual answer:  American\n",
      "loss:  11.03278923034668\n",
      "\n",
      "question:  Tirebolu is located in <mask>.\n",
      "Top 5 predictions:   Istanbul Turkey Romania Ankara Budapest\n",
      "Actual answer:  Turkey\n",
      "loss:  2.4077606201171875\n",
      "\n",
      "question:  Nizhneserginsky District is located in the country of <mask>.\n",
      "Top 5 predictions:   Russia Azerbaijan Armenia Belarus Ukraine\n",
      "Actual answer:  Russia\n",
      "loss:  1.2757822275161743\n",
      "\n",
      "question:  Colony of Vancouver Island, which has the capital city <mask>.\n",
      "Top 5 predictions:   Victoria Vancouver here Richmond Toronto\n",
      "Actual answer:  Victoria\n",
      "loss:  0.5265427231788635\n",
      "\n",
      "question:  Orkut, by <mask>.\n",
      "Top 5 predictions:   default design itself contrast proxy\n",
      "Actual answer:  Google\n",
      "loss:  4.643359184265137\n",
      "\n",
      "question:  Lilla Cabot Perry was native to <mask>.\n",
      "Top 5 predictions:   Virginia Louisiana Scotland Massachusetts Maine\n",
      "Actual answer:  Boston\n",
      "loss:  4.912285804748535\n",
      "\n",
      "question:  Megasport Arena can be found in <mask>.\n",
      "Top 5 predictions:   Valencia Singapore Cologne Tokyo Barcelona\n",
      "Actual answer:  Moscow\n",
      "loss:  4.269521713256836\n",
      "\n",
      "question:  The language of Candide, ou l'Optimisme was <mask>.\n",
      "Top 5 predictions:   French spoken lost gone dying\n",
      "Actual answer:  French\n",
      "loss:  1.383377194404602\n",
      "\n",
      "question:  The original language of The Next Day is <mask>.\n",
      "Top 5 predictions:   French English German Spanish Portuguese\n",
      "Actual answer:  English\n",
      "loss:  1.89191734790802\n",
      "\n",
      "question:  Sonic Underground was formulated in <mask>.\n",
      "Top 5 predictions:   1996 1997 1994 1999 1992\n",
      "Actual answer:  France\n",
      "loss:  6.951425552368164\n",
      "\n",
      "question:  Dick King-Smith speaks <mask>.\n",
      "Top 5 predictions:   out up today here again\n",
      "Actual answer:  English\n",
      "loss:  9.048104286193848\n",
      "\n",
      "question:  Leterrier is native to <mask>.\n",
      "Top 5 predictions:   Madagascar Australia Africa Brazil Canada\n",
      "Actual answer:  Paris\n",
      "loss:  7.965320110321045\n",
      "\n",
      "question:  Tokyo Jihen, founded in <mask>.\n",
      "Top 5 predictions:   1889 1910 1909 1908 1912\n",
      "Actual answer:  Japan\n",
      "loss:  9.184639930725098\n",
      "\n",
      "question:  Babylas of Antioch's position is <mask>.\n",
      "Top 5 predictions:   unclear unknown uncertain disputed unchanged\n",
      "Actual answer:  bishop\n",
      "loss:  10.91940689086914\n",
      "\n",
      "question:  Finland belongs to the continent of <mask>.\n",
      "Top 5 predictions:   Europe Asia Nordic Finland European\n",
      "Actual answer:  Europe\n",
      "loss:  0.017563175410032272\n",
      "\n",
      "question:  The occupation of Henny Moan is <mask>.\n",
      "Top 5 predictions:   ongoing illegal continuing over underway\n",
      "Actual answer:  actor\n",
      "loss:  16.06949234008789\n",
      "\n",
      "question:  O'Hare International Airport is owned by <mask>.\n",
      "Top 5 predictions:   Chicago ICE Illinois CPS Boeing\n",
      "Actual answer:  Chicago\n",
      "loss:  0.12444878369569778\n",
      "\n",
      "question:  The language of Red Cavalry was <mask>.\n",
      "Top 5 predictions:   Russian French German Latin English\n",
      "Actual answer:  Russian\n",
      "loss:  1.6515965461730957\n",
      "\n",
      "question:  Keith Fordyce is employed by <mask>.\n",
      "Top 5 predictions:  : IBM Google</s> Microsoft\n",
      "Actual answer:  BBC\n",
      "loss:  7.7491559982299805\n",
      "\n",
      "question:  Greta Van Susteren works for <mask>.\n",
      "Top 5 predictions:   Reuters Bloomberg CNN Greenpeace TIME\n",
      "Actual answer:  CNN\n",
      "loss:  2.4020447731018066\n",
      "\n",
      "question:  Celestiial, founded in <mask>.\n",
      "Top 5 predictions:   2008 2004 2006 2012 2007\n",
      "Actual answer:  Minnesota\n",
      "loss:  10.215994834899902\n",
      "\n",
      "question:  Motion City Soundtrack originated in <mask>.\n",
      "Top 5 predictions:   1984 1997 2003 1988 1987\n",
      "Actual answer:  American\n",
      "loss:  10.623077392578125\n",
      "\n",
      "question:  Michel Aumont, speaker of <mask>.\n",
      "Top 5 predictions:   parliament Parliament France government Congress\n",
      "Actual answer:  French\n",
      "loss:  7.5226640701293945\n",
      "\n",
      "question:  Good Sports originally aired on <mask>.\n",
      "Top 5 predictions:   NBC ESPN ABC CBS Fox\n",
      "Actual answer:  CBS\n",
      "loss:  2.0846006870269775\n",
      "\n",
      "question:  Totopo, that was developed in <mask>.\n",
      "Top 5 predictions:   Japan China 2006 Germany France\n",
      "Actual answer:  Mexico\n",
      "loss:  5.027066230773926\n",
      "\n",
      "question:  Eiffel Tower can be found in <mask>.\n",
      "Top 5 predictions:   Paris France French Europe Wikipedia\n",
      "Actual answer:  Paris\n",
      "loss:  0.38947218656539917\n",
      "\n",
      "question:  The law in Stellaland declares the language <mask>.\n",
      "Top 5 predictions:   taboo illegal genocide forbidden unacceptable\n",
      "Actual answer:  Dutch\n",
      "loss:  9.377181053161621\n",
      "\n",
      "question:  Sue Lawley, who works for <mask>.\n",
      "Top 5 predictions:   CNN NPR Google Uber MSNBC\n",
      "Actual answer:  BBC\n",
      "loss:  7.604353904724121\n",
      "\n",
      "question:  Whitworth gun was employed in <mask>.\n",
      "Top 5 predictions:   Germany 1936 1948 1947 1943\n",
      "Actual answer:  Manchester\n",
      "loss:  7.486306190490723\n",
      "\n",
      "question:  Partners HealthCare, whose headquarters are in <mask>.\n",
      "Top 5 predictions:   Atlanta Indianapolis Dallas Boston Chicago\n",
      "Actual answer:  Boston\n",
      "loss:  2.940119504928589\n",
      "\n",
      "question:  Rockabilly, that was created in <mask>.\n",
      "Top 5 predictions:   1969 1978 1976 1977 1968\n",
      "Actual answer:  American\n",
      "loss:  10.354110717773438\n",
      "\n",
      "question:  The language of Le chalet is <mask>.\n",
      "Top 5 predictions:   French English french German Dutch\n",
      "Actual answer:  French\n",
      "loss:  0.17566709220409393\n",
      "\n",
      "question:  The language of The Shining Star is <mask>.\n",
      "Top 5 predictions:   English French Hebrew Chinese Japanese\n",
      "Actual answer:  Chinese\n",
      "loss:  3.1093645095825195\n",
      "\n",
      "question:  Le Bureau was formulated in <mask>.\n",
      "Top 5 predictions:   Paris France 1946 1968 1947\n",
      "Actual answer:  France\n",
      "loss:  3.7830262184143066\n",
      "\n",
      "question:  INXS, formulated in <mask>.\n",
      "Top 5 predictions:   Australia England Germany Canada America\n",
      "Actual answer:  Australia\n",
      "loss:  3.0137531757354736\n",
      "\n",
      "question:  MCS-51, developed by <mask>.\n",
      "Top 5 predictions:   NASA IBM MIT Boeing Lockheed\n",
      "Actual answer:  Intel\n",
      "loss:  4.954118728637695\n",
      "\n",
      "question:  Morris Carnovsky, who works as <mask>.\n",
      "Top 5 predictions:   Mr a Dr Ms Mrs\n",
      "Actual answer:  actor\n",
      "loss:  7.394443511962891\n",
      "\n",
      "question:  The mother tongue of Marcel Schwob is <mask>.\n",
      "Top 5 predictions:   German French Czech Polish Hungarian\n",
      "Actual answer:  French\n",
      "loss:  2.646336078643799\n",
      "\n",
      "question:  Jon Cruddas found employment in <mask>.\n",
      "Top 5 predictions:   London Australia 2016 2008 2015\n",
      "Actual answer:  London\n",
      "loss:  3.589099645614624\n",
      "\n",
      "question:  The language used by Musa Manarov is <mask>.\n",
      "Top 5 predictions:   Russian Persian Armenian Arabic English\n",
      "Actual answer:  Russian\n",
      "loss:  1.7429306507110596\n",
      "\n",
      "question:  Bild was written in <mask>.\n",
      "Top 5 predictions:   German English French Russian Spanish\n",
      "Actual answer:  German\n",
      "loss:  0.20750698447227478\n",
      "\n",
      "question:  Guster, founded in <mask>.\n",
      "Top 5 predictions:   2008 2012 2010 2013 2006\n",
      "Actual answer:  Boston\n",
      "loss:  7.366535663604736\n",
      "\n",
      "question:  Jon Sopel is employed by <mask>.\n",
      "Top 5 predictions:   HBO CNN CBS NBC Reuters\n",
      "Actual answer:  BBC\n",
      "loss:  6.006754398345947\n",
      "\n",
      "question:  Office Live is developed by <mask>.\n",
      "Top 5 predictions:   Microsoft Adobe Google IBM Oracle\n",
      "Actual answer:  Microsoft\n",
      "loss:  0.09070180356502533\n",
      "\n",
      "question:  Marie Franois Oscar Bardy de Fourtou died in <mask>.\n",
      "Top 5 predictions:   Paris 1942 1958 1932 1955\n",
      "Actual answer:  Paris\n",
      "loss:  4.058136463165283\n",
      "\n",
      "question:  Zeroman was developed in <mask>.\n",
      "Top 5 predictions:   1999 2006 1996 2005 2003\n",
      "Actual answer:  Canada\n",
      "loss:  5.569921016693115\n",
      "\n",
      "question:  Cadillac's headquarters are in <mask>.\n",
      "Top 5 predictions:   Detroit Michigan Lansing Atlanta Chicago\n",
      "Actual answer:  Detroit\n",
      "loss:  0.7115166187286377\n",
      "\n",
      "question:  DYS formed in <mask>.\n",
      "Top 5 predictions:   1996 1997 1999 1994 1992\n",
      "Actual answer:  Boston\n",
      "loss:  8.986396789550781\n",
      "\n",
      "question:  The original language of Akenfield was <mask>.\n",
      "Top 5 predictions:   German French English Dutch Latin\n",
      "Actual answer:  English\n",
      "loss:  2.087437152862549\n",
      "\n",
      "question:  The occupation of Troy Donahue is <mask>.\n",
      "Top 5 predictions:   ongoing over illegal continuing underway\n",
      "Actual answer:  actor\n",
      "loss:  15.218538284301758\n",
      "\n",
      "question:  The Bronx Is Burning originally aired on <mask>.\n",
      "Top 5 predictions:   Bravo HBO NBC CBS Showtime\n",
      "Actual answer:  ESPN\n",
      "loss:  6.045332908630371\n",
      "\n",
      "question:  Pascal Dagnan-Bouveret writes in <mask>.\n",
      "Top 5 predictions:   French Paris France English Nature\n",
      "Actual answer:  French\n",
      "loss:  0.32594412565231323\n",
      "\n",
      "question:  The Krofft Superstar Hour was released on <mask>.\n",
      "Top 5 predictions:   DVD CD iTunes vinyl Friday\n",
      "Actual answer:  NBC\n",
      "loss:  11.220532417297363\n",
      "\n",
      "question:  Royal Mint, that was created in <mask>.\n",
      "Top 5 predictions:   1913 1926 1893 1911 1909\n",
      "Actual answer:  London\n",
      "loss:  5.236084938049316\n",
      "\n",
      "question:  Income Property, that originated in <mask>.\n",
      "Top 5 predictions:   Canada 2008 England 2007 Australia\n",
      "Actual answer:  Canada\n",
      "loss:  2.6244146823883057\n",
      "\n",
      "question:  Lufkin is within <mask>.\n",
      "Top 5 predictions:   reach sight range view grasp\n",
      "Actual answer:  Texas\n",
      "loss:  9.222722053527832\n",
      "\n",
      "question:  British Museum is located in <mask>.\n",
      "Top 5 predictions:   London Westminster Greenwich Birmingham Edinburgh\n",
      "Actual answer:  London\n",
      "loss:  0.002785732736811042\n",
      "\n",
      "question:  Sena Medal, located in <mask>.\n",
      "Top 5 predictions:   Tokyo London Japan Vienna Bangkok\n",
      "Actual answer:  India\n",
      "loss:  4.448158264160156\n",
      "\n",
      "question:  Girl Authority, that was formulated in <mask>.\n",
      "Top 5 predictions:   1994 1997 1991 1996 1995\n",
      "Actual answer:  American\n",
      "loss:  10.411550521850586\n",
      "\n",
      "question:  The original language of Brut y Tywysogion is <mask>.\n",
      "Top 5 predictions:   Welsh English Polish Catalan Irish\n",
      "Actual answer:  Latin\n",
      "loss:  7.555431842803955\n",
      "\n",
      "question:  John Dalton, speaker of <mask>.\n",
      "Top 5 predictions:   Congress Rep Parliament parliament House\n",
      "Actual answer:  English\n",
      "loss:  8.29218864440918\n",
      "\n",
      "question:  The original language of Tehran Times is <mask>.\n",
      "Top 5 predictions:   Persian English Arabic French Kurdish\n",
      "Actual answer:  English\n",
      "loss:  1.1679534912109375\n",
      "\n",
      "question:  Bilecik Province, which is located in <mask>.\n",
      "Top 5 predictions:   Serbia Kosovo Turkey Albania Azerbaijan\n",
      "Actual answer:  Turkey\n",
      "loss:  2.2872304916381836\n",
      "\n",
      "Average Loss: 5.304989384661894\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "reference_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, question in enumerate(questions_masked):\n",
    "\n",
    "        # see example in: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForMaskedLM\n",
    "        inputs = tokenizer(question, return_tensors='pt')\n",
    "\n",
    "        question_with_answer = questions[i] + \" \" + answers[i] + \".\"\n",
    "\n",
    "        print(\"question: \", question)\n",
    "        \n",
    "        labels = tokenizer(question_with_answer, return_tensors='pt')[\"input_ids\"]\n",
    "        labels = torch.where(inputs.input_ids == tokenizer.mask_token_id, labels, -100)\n",
    "\n",
    "        outputs = reference_model(**inputs, labels=labels)\n",
    "        mask_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "        top_5_preds = torch.topk(outputs.logits[0, mask_index, :], 5, dim=1).indices[0].tolist()\n",
    "\n",
    "        print(\"Top 5 predictions: \", tokenizer.decode(top_5_preds))\n",
    "        print(\"Actual answer: \", answers[i])\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "        print(\"loss: \", loss.item())\n",
    "        print(\"\")\n",
    "\n",
    "print(f\"Average Loss: {sum(losses) / len(losses)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'K'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([530])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing JudgeLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
