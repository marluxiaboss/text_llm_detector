{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict, concatenate_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label: true = 0, fake = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"gemma_chat_10k\"\n",
    "fake_train_dataset_df = pd.read_json(f\"fake_true_datasets/fake_true_dataset_{experiment_name}_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Four groups that advocate for immigrant right...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Former Vice President Dick Cheney on Sunday d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Former Vice President Dick Cheney on Sunday d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Space shuttle Discovery launched just before ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Space shuttle Discovery launched just before ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14199</th>\n",
       "      <td>[The Federal Aviation Administration ordered U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14200</th>\n",
       "      <td>[A Web designer in London was amazed to discov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14201</th>\n",
       "      <td>[A Web designer in London was amazed to discov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14202</th>\n",
       "      <td>[The mother of a 17-year-old girl who disappea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14203</th>\n",
       "      <td>[The mother of a 17-year-old girl who disappea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14204 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      [Four groups that advocate for immigrant right...      1\n",
       "1      [Former Vice President Dick Cheney on Sunday d...      1\n",
       "2      [Former Vice President Dick Cheney on Sunday d...      0\n",
       "3      [Space shuttle Discovery launched just before ...      1\n",
       "4      [Space shuttle Discovery launched just before ...      0\n",
       "...                                                  ...    ...\n",
       "14199  [The Federal Aviation Administration ordered U...      1\n",
       "14200  [A Web designer in London was amazed to discov...      1\n",
       "14201  [A Web designer in London was amazed to discov...      0\n",
       "14202  [The mother of a 17-year-old girl who disappea...      1\n",
       "14203  [The mother of a 17-year-old girl who disappea...      0\n",
       "\n",
       "[14204 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Four groups that advocate for immigrant rights said Thursday they would continue their fight for a pathway to citizenship for undocumented immigrants, despite recent setbacks in the legislative process. The Immigration Reform Coalition, the National Immigration Forum, the United Way for Immigration, and the American Civil Liberties Union (ACLU) made the statement as they joined forces to urge lawmakers to prioritize the issue of undocumented immigration reform. \"The fight for immigrant rights is'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df.iloc[0][\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_dataset_df[\"text_sentences\"] = fake_train_dataset_df[\"text\"].apply(lambda x: x[0].split(\".\"))\n",
    "\n",
    "fake_texts_df = fake_train_dataset_df[fake_train_dataset_df[\"label\"] == 1]\n",
    "true_texts_df = fake_train_dataset_df[fake_train_dataset_df[\"label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Four groups that advocate for immigrant rights said Thursday they would continue their fight for a pathway to citizenship for undocumented immigrants, despite recent setbacks in the legislative process',\n",
       " ' The Immigration Reform Coalition, the National Immigration Forum, the United Way for Immigration, and the American Civil Liberties Union (ACLU) made the statement as they joined forces to urge lawmakers to prioritize the issue of undocumented immigration reform',\n",
       " ' \"The fight for immigrant rights is']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df[\"text_sentences\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences in fake texts: 4.673937517590768\n",
      "Average number of sentences in true texts: 5.242885319808397\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average number of sentences in fake texts: {np.mean(fake_texts_df['text_sentences'].apply(len))}\")\n",
    "print(f\"Average number of sentences in true texts: {np.mean(true_texts_df['text_sentences'].apply(len))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of 'the' in fake texts: 5.513650436251056\n",
      "Average number of 'the' in true texts: 5.121442659904198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_153047/176004568.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_texts_df[\"the_count\"] = fake_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
      "/tmp/ipykernel_153047/176004568.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  true_texts_df[\"the_count\"] = true_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n"
     ]
    }
   ],
   "source": [
    "# add column: number of \"the\" in text\n",
    "fake_texts_df[\"the_count\"] = fake_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
    "true_texts_df[\"the_count\"] = true_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
    "\n",
    "print(f\"Average number of 'the' in fake texts: {np.mean(fake_texts_df['the_count'])}\")\n",
    "print(f\"Average number of 'the' in true texts: {np.mean(true_texts_df['the_count'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_dataset_full_text = \" \".join([text for text in fake_train_dataset_df[\"text\"].apply(lambda x: x[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7116203"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_train_dataset_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through all the texts and count occurence of each characters in unicode representation\n",
    "\n",
    "def count_chars(texts):\n",
    "    char_counts = {}\n",
    "    for text in texts:\n",
    "        for char in text:\n",
    "            if char in char_counts:\n",
    "                char_counts[char] += 1\n",
    "            else:\n",
    "                char_counts[char] = 1\n",
    "    return char_counts\n",
    "\n",
    "fake_char_counts = count_chars(fake_train_dataset_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1165616,\n",
       " 'e': 681185,\n",
       " 'a': 495961,\n",
       " 't': 457634,\n",
       " 'i': 428984,\n",
       " 'n': 419228,\n",
       " 'o': 397668,\n",
       " 's': 365089,\n",
       " 'r': 360793,\n",
       " 'h': 260497,\n",
       " 'd': 230793,\n",
       " 'l': 219325,\n",
       " 'c': 181788,\n",
       " 'u': 144796,\n",
       " 'm': 126976,\n",
       " 'f': 119782,\n",
       " 'g': 118167,\n",
       " 'p': 104800,\n",
       " 'y': 91513,\n",
       " 'w': 87421,\n",
       " 'b': 70961,\n",
       " ',': 69396,\n",
       " 'v': 57288,\n",
       " '.': 56223,\n",
       " 'k': 39438,\n",
       " 'T': 30983,\n",
       " 'S': 20639,\n",
       " 'A': 20602,\n",
       " '-': 18010,\n",
       " '\"': 16882,\n",
       " \"'\": 16057,\n",
       " 'C': 15502,\n",
       " 'M': 13674,\n",
       " 'I': 13075,\n",
       " '0': 12363,\n",
       " 'P': 10365,\n",
       " 'B': 10233,\n",
       " 'x': 9932,\n",
       " 'H': 9510,\n",
       " 'N': 8695,\n",
       " 'W': 8655,\n",
       " '1': 8412,\n",
       " 'F': 8336,\n",
       " '2': 7968,\n",
       " 'D': 7540,\n",
       " 'j': 7137,\n",
       " 'z': 6591,\n",
       " 'R': 6398,\n",
       " 'L': 6098,\n",
       " 'J': 5890,\n",
       " 'O': 5809,\n",
       " 'G': 5483,\n",
       " 'U': 5260,\n",
       " 'q': 4608,\n",
       " 'E': 4524,\n",
       " 'K': 3824,\n",
       " '3': 3599,\n",
       " '5': 3481,\n",
       " '9': 2832,\n",
       " '4': 2604,\n",
       " 'V': 2514,\n",
       " '*': 2438,\n",
       " '8': 2244,\n",
       " '7': 2233,\n",
       " '6': 2161,\n",
       " ':': 1826,\n",
       " 'Y': 1696,\n",
       " '(': 1413,\n",
       " ')': 1381,\n",
       " '$': 902,\n",
       " 'Z': 761,\n",
       " '?': 553,\n",
       " 'Q': 543,\n",
       " '[': 527,\n",
       " ']': 515,\n",
       " ';': 246,\n",
       " '%': 238,\n",
       " 'X': 191,\n",
       " '!': 177,\n",
       " '/': 154,\n",
       " '&': 129,\n",
       " 'Ã©': 81,\n",
       " '+': 45,\n",
       " 'Â£': 36,\n",
       " 'â€¢': 31,\n",
       " 'Ã³': 21,\n",
       " 'Ã¡': 21,\n",
       " 'Ã­': 16,\n",
       " 'Â½': 15,\n",
       " 'â‚¬': 15,\n",
       " 'Ã±': 14,\n",
       " 'Ã£': 13,\n",
       " 'Â°': 12,\n",
       " 'â€“': 12,\n",
       " 'Â»': 9,\n",
       " 'Ã¼': 8,\n",
       " 'â€œ': 8,\n",
       " '#': 8,\n",
       " 'Ã': 8,\n",
       " 'Ä‡': 8,\n",
       " 'â€”': 6,\n",
       " 'Ã¶': 5,\n",
       " 'â€': 5,\n",
       " 'Ã¨': 5,\n",
       " 'Ã§': 5,\n",
       " 'Ã¤': 5,\n",
       " '_': 5,\n",
       " '\\\\': 4,\n",
       " 'Ãº': 4,\n",
       " '\\xad': 3,\n",
       " 'Ã¸': 2,\n",
       " 'â€™': 2,\n",
       " 'Ä±': 2,\n",
       " 'Ã¾': 2,\n",
       " 'Ã¯': 2,\n",
       " '|': 2,\n",
       " 'ÄŸ': 2,\n",
       " 'Ã‰': 2,\n",
       " 'â‚¹': 2,\n",
       " 'Å¡': 2,\n",
       " 'Å¾': 2,\n",
       " 'Ã¢': 1,\n",
       " 'Ã´': 1,\n",
       " '@': 1,\n",
       " '>': 1,\n",
       " 'Ã ': 1,\n",
       " 'Åž': 1,\n",
       " 'Å›': 1,\n",
       " 'Ã«': 1,\n",
       " 'Â®': 1,\n",
       " 'Ã»': 1,\n",
       " 'Ä': 1,\n",
       " 'ðŸ‘‘': 1,\n",
       " 'ðŸ’•': 1,\n",
       " 'Å„': 1,\n",
       " 'Â¥': 1,\n",
       " 'Ã¥': 1,\n",
       " 'Ã˜': 1,\n",
       " 'Äƒ': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_char_counts_sorted = dict(sorted(fake_char_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "fake_char_counts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{32: 1165616,\n",
       " 101: 681185,\n",
       " 97: 495961,\n",
       " 116: 457634,\n",
       " 105: 428984,\n",
       " 110: 419228,\n",
       " 111: 397668,\n",
       " 115: 365089,\n",
       " 114: 360793,\n",
       " 104: 260497,\n",
       " 100: 230793,\n",
       " 108: 219325,\n",
       " 99: 181788,\n",
       " 117: 144796,\n",
       " 109: 126976,\n",
       " 102: 119782,\n",
       " 103: 118167,\n",
       " 112: 104800,\n",
       " 121: 91513,\n",
       " 119: 87421,\n",
       " 98: 70961,\n",
       " 44: 69396,\n",
       " 118: 57288,\n",
       " 46: 56223,\n",
       " 107: 39438,\n",
       " 84: 30983,\n",
       " 83: 20639,\n",
       " 65: 20602,\n",
       " 45: 18010,\n",
       " 34: 16882,\n",
       " 39: 16057,\n",
       " 67: 15502,\n",
       " 77: 13674,\n",
       " 73: 13075,\n",
       " 48: 12363,\n",
       " 80: 10365,\n",
       " 66: 10233,\n",
       " 120: 9932,\n",
       " 72: 9510,\n",
       " 78: 8695,\n",
       " 87: 8655,\n",
       " 49: 8412,\n",
       " 70: 8336,\n",
       " 50: 7968,\n",
       " 68: 7540,\n",
       " 106: 7137,\n",
       " 122: 6591,\n",
       " 82: 6398,\n",
       " 76: 6098,\n",
       " 74: 5890,\n",
       " 79: 5809,\n",
       " 71: 5483,\n",
       " 85: 5260,\n",
       " 113: 4608,\n",
       " 69: 4524,\n",
       " 75: 3824,\n",
       " 51: 3599,\n",
       " 53: 3481,\n",
       " 57: 2832,\n",
       " 52: 2604,\n",
       " 86: 2514,\n",
       " 42: 2438,\n",
       " 56: 2244,\n",
       " 55: 2233,\n",
       " 54: 2161,\n",
       " 58: 1826,\n",
       " 89: 1696,\n",
       " 40: 1413,\n",
       " 41: 1381,\n",
       " 36: 902,\n",
       " 90: 761,\n",
       " 63: 553,\n",
       " 81: 543,\n",
       " 91: 527,\n",
       " 93: 515,\n",
       " 59: 246,\n",
       " 37: 238,\n",
       " 88: 191,\n",
       " 33: 177,\n",
       " 47: 154,\n",
       " 38: 129,\n",
       " 233: 81,\n",
       " 43: 45,\n",
       " 163: 36,\n",
       " 8226: 31,\n",
       " 243: 21,\n",
       " 225: 21,\n",
       " 237: 16,\n",
       " 189: 15,\n",
       " 8364: 15,\n",
       " 241: 14,\n",
       " 227: 13,\n",
       " 176: 12,\n",
       " 8211: 12,\n",
       " 187: 9,\n",
       " 252: 8,\n",
       " 8220: 8,\n",
       " 35: 8,\n",
       " 193: 8,\n",
       " 263: 8,\n",
       " 8212: 6,\n",
       " 246: 5,\n",
       " 8221: 5,\n",
       " 232: 5,\n",
       " 231: 5,\n",
       " 228: 5,\n",
       " 95: 5,\n",
       " 92: 4,\n",
       " 250: 4,\n",
       " 173: 3,\n",
       " 248: 2,\n",
       " 8217: 2,\n",
       " 305: 2,\n",
       " 254: 2,\n",
       " 239: 2,\n",
       " 124: 2,\n",
       " 287: 2,\n",
       " 201: 2,\n",
       " 8377: 2,\n",
       " 353: 2,\n",
       " 382: 2,\n",
       " 226: 1,\n",
       " 244: 1,\n",
       " 64: 1,\n",
       " 62: 1,\n",
       " 224: 1,\n",
       " 350: 1,\n",
       " 347: 1,\n",
       " 235: 1,\n",
       " 174: 1,\n",
       " 251: 1,\n",
       " 257: 1,\n",
       " 128081: 1,\n",
       " 128149: 1,\n",
       " 324: 1,\n",
       " 165: 1,\n",
       " 229: 1,\n",
       " 216: 1,\n",
       " 259: 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert keys in char_counts to unicode\n",
    "fake_char_counts_unicode = {ord(k): v for k, v in fake_char_counts_sorted.items()}\n",
    "fake_char_counts_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ã©': 81,\n",
       " 'Â£': 36,\n",
       " 'â€¢': 31,\n",
       " 'Ã³': 21,\n",
       " 'Ã¡': 21,\n",
       " 'Ã­': 16,\n",
       " 'Â½': 15,\n",
       " 'â‚¬': 15,\n",
       " 'Ã±': 14,\n",
       " 'Ã£': 13,\n",
       " 'Â°': 12,\n",
       " 'â€“': 12,\n",
       " 'Â»': 9,\n",
       " 'Ã¼': 8,\n",
       " 'â€œ': 8,\n",
       " 'Ã': 8,\n",
       " 'Ä‡': 8,\n",
       " 'â€”': 6,\n",
       " 'Ã¶': 5,\n",
       " 'â€': 5,\n",
       " 'Ã¨': 5,\n",
       " 'Ã§': 5,\n",
       " 'Ã¤': 5,\n",
       " 'Ãº': 4,\n",
       " '\\xad': 3,\n",
       " 'Ã¸': 2,\n",
       " 'â€™': 2,\n",
       " 'Ä±': 2,\n",
       " 'Ã¾': 2,\n",
       " 'Ã¯': 2,\n",
       " 'ÄŸ': 2,\n",
       " 'Ã‰': 2,\n",
       " 'â‚¹': 2,\n",
       " 'Å¡': 2,\n",
       " 'Å¾': 2,\n",
       " 'Ã¢': 1,\n",
       " 'Ã´': 1,\n",
       " 'Ã ': 1,\n",
       " 'Åž': 1,\n",
       " 'Å›': 1,\n",
       " 'Ã«': 1,\n",
       " 'Â®': 1,\n",
       " 'Ã»': 1,\n",
       " 'Ä': 1,\n",
       " 'ðŸ‘‘': 1,\n",
       " 'ðŸ’•': 1,\n",
       " 'Å„': 1,\n",
       " 'Â¥': 1,\n",
       " 'Ã¥': 1,\n",
       " 'Ã˜': 1,\n",
       " 'Äƒ': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude from count all ascii characters, ie. all keys above 128\n",
    "fake_char_counts_special = {k: v for k, v in fake_char_counts_sorted.items() if ord(k) > 128}\n",
    "fake_char_counts_special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal apostrophes: 6457\n",
      "Number of special apostrophes: 2\n"
     ]
    }
   ],
   "source": [
    "# count different kind of apostrophes\n",
    "count_apostrophe_type_1 = 0\n",
    "count_apostrophe_type_2 = 0\n",
    "\n",
    "# iterate over fake texts and count occurence of different apostrophes\n",
    "for text in fake_texts_df[\"text\"].apply(lambda x: x[0]):\n",
    "    count_apostrophe_type_1 += text.count(\"'\")\n",
    "    count_apostrophe_type_2 += text.count(\"â€™\")\n",
    "\n",
    "print(f\"Number of normal apostrophes: {count_apostrophe_type_1}\")\n",
    "print(f\"Number of special apostrophes: {count_apostrophe_type_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'â€”'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert form unicode to character\n",
    "chr(8212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'â€“'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(8211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
